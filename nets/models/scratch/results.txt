I0825 12:15:00.319470  6868 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: nets/models/scratch/tracker.prototxt
I0825 12:15:00.328582  6868 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0825 12:15:00.328598  6868 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0825 12:15:00.345049  6868 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "target"
  top: "image"
  top: "bbox"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 4
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "target"
  top: "conv1"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "image"
  top: "conv1_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "pool1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "norm1_p"
  top: "conv2_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "pool2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "norm2_p"
  top: "conv3_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "conv5_p"
  type: "Convolution"
  bottom: "conv4_p"
  top: "conv5_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5_p"
  type: "ReLU"
  bottom: "conv5_p"
  top: "conv5_p"
}
layer {
  name: "pool5_p"
  type: "Pooling"
  bottom: "conv5_p"
  top: "pool5_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "pool5"
  bottom: "pool5_p"
  top: "pool5_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc6-new"
  type: "InnerProduct"
  bottom: "pool5_concat"
  top: "fc6"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-newb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc7b"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7b"
  type: "ReLU"
  bottom: "fc7b"
  top: "fc7b"
}
layer {
  name: "drop7b"
  type: "Dropout"
  bottom: "fc7b"
  top: "fc7b"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-shapes"
  type: "InnerProduct"
  bottom: "fc7b"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "neg"
  type: "Power"
  bottom: "bbox"
  top: "bbox_neg"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "bbox_neg"
  top: "bbox_neg_flat"
}
layer {
  name: "subtract"
  type: "Eltwise"
  bottom: "fc8"
  bottom: "bbox_neg_flat"
  top: "out_diff"
}
layer {
  name: "abssum"
  type: "Reduction"
  bottom: "out_diff"
  top: "loss"
  loss_weight: 1
  reduction_param {
    operation: ASUM
  }
}
I0825 12:15:00.345226  6868 layer_factory.hpp:77] Creating layer input
I0825 12:15:00.345247  6868 net.cpp:100] Creating Layer input
I0825 12:15:00.345255  6868 net.cpp:408] input -> target
I0825 12:15:00.345288  6868 net.cpp:408] input -> image
I0825 12:15:00.345300  6868 net.cpp:408] input -> bbox
I0825 12:15:00.353029  6868 net.cpp:150] Setting up input
I0825 12:15:00.353080  6868 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0825 12:15:00.353087  6868 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0825 12:15:00.353092  6868 net.cpp:157] Top shape: 1 4 1 1 (4)
I0825 12:15:00.353096  6868 net.cpp:165] Memory required for data: 1236712
I0825 12:15:00.353107  6868 layer_factory.hpp:77] Creating layer conv1
I0825 12:15:00.353132  6868 net.cpp:100] Creating Layer conv1
I0825 12:15:00.353139  6868 net.cpp:434] conv1 <- target
I0825 12:15:00.353152  6868 net.cpp:408] conv1 -> conv1
I0825 12:15:00.460129  6868 net.cpp:150] Setting up conv1
I0825 12:15:00.460170  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:00.460175  6868 net.cpp:165] Memory required for data: 2398312
I0825 12:15:00.460199  6868 layer_factory.hpp:77] Creating layer relu1
I0825 12:15:00.460213  6868 net.cpp:100] Creating Layer relu1
I0825 12:15:00.460218  6868 net.cpp:434] relu1 <- conv1
I0825 12:15:00.460225  6868 net.cpp:395] relu1 -> conv1 (in-place)
I0825 12:15:00.460397  6868 net.cpp:150] Setting up relu1
I0825 12:15:00.460407  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:00.460410  6868 net.cpp:165] Memory required for data: 3559912
I0825 12:15:00.460413  6868 layer_factory.hpp:77] Creating layer pool1
I0825 12:15:00.460423  6868 net.cpp:100] Creating Layer pool1
I0825 12:15:00.460428  6868 net.cpp:434] pool1 <- conv1
I0825 12:15:00.460434  6868 net.cpp:408] pool1 -> pool1
I0825 12:15:00.460477  6868 net.cpp:150] Setting up pool1
I0825 12:15:00.460484  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:00.460487  6868 net.cpp:165] Memory required for data: 3839848
I0825 12:15:00.460491  6868 layer_factory.hpp:77] Creating layer norm1
I0825 12:15:00.460501  6868 net.cpp:100] Creating Layer norm1
I0825 12:15:00.460505  6868 net.cpp:434] norm1 <- pool1
I0825 12:15:00.460510  6868 net.cpp:408] norm1 -> norm1
I0825 12:15:00.460747  6868 net.cpp:150] Setting up norm1
I0825 12:15:00.460758  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:00.460762  6868 net.cpp:165] Memory required for data: 4119784
I0825 12:15:00.460767  6868 layer_factory.hpp:77] Creating layer conv2
I0825 12:15:00.460779  6868 net.cpp:100] Creating Layer conv2
I0825 12:15:00.460783  6868 net.cpp:434] conv2 <- norm1
I0825 12:15:00.460789  6868 net.cpp:408] conv2 -> conv2
I0825 12:15:00.470592  6868 net.cpp:150] Setting up conv2
I0825 12:15:00.470631  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:00.470635  6868 net.cpp:165] Memory required for data: 4866280
I0825 12:15:00.470660  6868 layer_factory.hpp:77] Creating layer relu2
I0825 12:15:00.470672  6868 net.cpp:100] Creating Layer relu2
I0825 12:15:00.470677  6868 net.cpp:434] relu2 <- conv2
I0825 12:15:00.470685  6868 net.cpp:395] relu2 -> conv2 (in-place)
I0825 12:15:00.470826  6868 net.cpp:150] Setting up relu2
I0825 12:15:00.470836  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:00.470839  6868 net.cpp:165] Memory required for data: 5612776
I0825 12:15:00.470844  6868 layer_factory.hpp:77] Creating layer pool2
I0825 12:15:00.470850  6868 net.cpp:100] Creating Layer pool2
I0825 12:15:00.470854  6868 net.cpp:434] pool2 <- conv2
I0825 12:15:00.470860  6868 net.cpp:408] pool2 -> pool2
I0825 12:15:00.470896  6868 net.cpp:150] Setting up pool2
I0825 12:15:00.470901  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.470904  6868 net.cpp:165] Memory required for data: 5785832
I0825 12:15:00.470908  6868 layer_factory.hpp:77] Creating layer norm2
I0825 12:15:00.470917  6868 net.cpp:100] Creating Layer norm2
I0825 12:15:00.470921  6868 net.cpp:434] norm2 <- pool2
I0825 12:15:00.470927  6868 net.cpp:408] norm2 -> norm2
I0825 12:15:00.471170  6868 net.cpp:150] Setting up norm2
I0825 12:15:00.471181  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.471185  6868 net.cpp:165] Memory required for data: 5958888
I0825 12:15:00.471189  6868 layer_factory.hpp:77] Creating layer conv3
I0825 12:15:00.471204  6868 net.cpp:100] Creating Layer conv3
I0825 12:15:00.471207  6868 net.cpp:434] conv3 <- norm2
I0825 12:15:00.471215  6868 net.cpp:408] conv3 -> conv3
I0825 12:15:00.496065  6868 net.cpp:150] Setting up conv3
I0825 12:15:00.496110  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.496114  6868 net.cpp:165] Memory required for data: 6218472
I0825 12:15:00.496129  6868 layer_factory.hpp:77] Creating layer relu3
I0825 12:15:00.496140  6868 net.cpp:100] Creating Layer relu3
I0825 12:15:00.496145  6868 net.cpp:434] relu3 <- conv3
I0825 12:15:00.496151  6868 net.cpp:395] relu3 -> conv3 (in-place)
I0825 12:15:00.496378  6868 net.cpp:150] Setting up relu3
I0825 12:15:00.496390  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.496394  6868 net.cpp:165] Memory required for data: 6478056
I0825 12:15:00.496398  6868 layer_factory.hpp:77] Creating layer conv4
I0825 12:15:00.496409  6868 net.cpp:100] Creating Layer conv4
I0825 12:15:00.496413  6868 net.cpp:434] conv4 <- conv3
I0825 12:15:00.496420  6868 net.cpp:408] conv4 -> conv4
I0825 12:15:00.515676  6868 net.cpp:150] Setting up conv4
I0825 12:15:00.515715  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.515722  6868 net.cpp:165] Memory required for data: 6737640
I0825 12:15:00.515732  6868 layer_factory.hpp:77] Creating layer relu4
I0825 12:15:00.515744  6868 net.cpp:100] Creating Layer relu4
I0825 12:15:00.515749  6868 net.cpp:434] relu4 <- conv4
I0825 12:15:00.515756  6868 net.cpp:395] relu4 -> conv4 (in-place)
I0825 12:15:00.515890  6868 net.cpp:150] Setting up relu4
I0825 12:15:00.515899  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.515903  6868 net.cpp:165] Memory required for data: 6997224
I0825 12:15:00.515907  6868 layer_factory.hpp:77] Creating layer conv5
I0825 12:15:00.515918  6868 net.cpp:100] Creating Layer conv5
I0825 12:15:00.515923  6868 net.cpp:434] conv5 <- conv4
I0825 12:15:00.515929  6868 net.cpp:408] conv5 -> conv5
I0825 12:15:00.529155  6868 net.cpp:150] Setting up conv5
I0825 12:15:00.529194  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.529199  6868 net.cpp:165] Memory required for data: 7170280
I0825 12:15:00.529214  6868 layer_factory.hpp:77] Creating layer relu5
I0825 12:15:00.529225  6868 net.cpp:100] Creating Layer relu5
I0825 12:15:00.529232  6868 net.cpp:434] relu5 <- conv5
I0825 12:15:00.529237  6868 net.cpp:395] relu5 -> conv5 (in-place)
I0825 12:15:00.529475  6868 net.cpp:150] Setting up relu5
I0825 12:15:00.529487  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.529490  6868 net.cpp:165] Memory required for data: 7343336
I0825 12:15:00.529502  6868 layer_factory.hpp:77] Creating layer pool5
I0825 12:15:00.529510  6868 net.cpp:100] Creating Layer pool5
I0825 12:15:00.529515  6868 net.cpp:434] pool5 <- conv5
I0825 12:15:00.529521  6868 net.cpp:408] pool5 -> pool5
I0825 12:15:00.529557  6868 net.cpp:150] Setting up pool5
I0825 12:15:00.529563  6868 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0825 12:15:00.529567  6868 net.cpp:165] Memory required for data: 7380200
I0825 12:15:00.529570  6868 layer_factory.hpp:77] Creating layer conv1_p
I0825 12:15:00.529583  6868 net.cpp:100] Creating Layer conv1_p
I0825 12:15:00.529587  6868 net.cpp:434] conv1_p <- image
I0825 12:15:00.529593  6868 net.cpp:408] conv1_p -> conv1_p
I0825 12:15:00.531265  6868 net.cpp:150] Setting up conv1_p
I0825 12:15:00.531278  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:00.531282  6868 net.cpp:165] Memory required for data: 8541800
I0825 12:15:00.531289  6868 layer_factory.hpp:77] Creating layer relu1_p
I0825 12:15:00.531297  6868 net.cpp:100] Creating Layer relu1_p
I0825 12:15:00.531302  6868 net.cpp:434] relu1_p <- conv1_p
I0825 12:15:00.531308  6868 net.cpp:395] relu1_p -> conv1_p (in-place)
I0825 12:15:00.531527  6868 net.cpp:150] Setting up relu1_p
I0825 12:15:00.531539  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:00.531543  6868 net.cpp:165] Memory required for data: 9703400
I0825 12:15:00.531548  6868 layer_factory.hpp:77] Creating layer pool1_p
I0825 12:15:00.531553  6868 net.cpp:100] Creating Layer pool1_p
I0825 12:15:00.531558  6868 net.cpp:434] pool1_p <- conv1_p
I0825 12:15:00.531563  6868 net.cpp:408] pool1_p -> pool1_p
I0825 12:15:00.531596  6868 net.cpp:150] Setting up pool1_p
I0825 12:15:00.531602  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:00.531606  6868 net.cpp:165] Memory required for data: 9983336
I0825 12:15:00.531610  6868 layer_factory.hpp:77] Creating layer norm1_p
I0825 12:15:00.531617  6868 net.cpp:100] Creating Layer norm1_p
I0825 12:15:00.531620  6868 net.cpp:434] norm1_p <- pool1_p
I0825 12:15:00.531625  6868 net.cpp:408] norm1_p -> norm1_p
I0825 12:15:00.531771  6868 net.cpp:150] Setting up norm1_p
I0825 12:15:00.531780  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:00.531785  6868 net.cpp:165] Memory required for data: 10263272
I0825 12:15:00.531787  6868 layer_factory.hpp:77] Creating layer conv2_p
I0825 12:15:00.531796  6868 net.cpp:100] Creating Layer conv2_p
I0825 12:15:00.531800  6868 net.cpp:434] conv2_p <- norm1_p
I0825 12:15:00.531806  6868 net.cpp:408] conv2_p -> conv2_p
I0825 12:15:00.541340  6868 net.cpp:150] Setting up conv2_p
I0825 12:15:00.541371  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:00.541378  6868 net.cpp:165] Memory required for data: 11009768
I0825 12:15:00.541388  6868 layer_factory.hpp:77] Creating layer relu2_p
I0825 12:15:00.541396  6868 net.cpp:100] Creating Layer relu2_p
I0825 12:15:00.541401  6868 net.cpp:434] relu2_p <- conv2_p
I0825 12:15:00.541407  6868 net.cpp:395] relu2_p -> conv2_p (in-place)
I0825 12:15:00.541541  6868 net.cpp:150] Setting up relu2_p
I0825 12:15:00.541549  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:00.541553  6868 net.cpp:165] Memory required for data: 11756264
I0825 12:15:00.541558  6868 layer_factory.hpp:77] Creating layer pool2_p
I0825 12:15:00.541563  6868 net.cpp:100] Creating Layer pool2_p
I0825 12:15:00.541568  6868 net.cpp:434] pool2_p <- conv2_p
I0825 12:15:00.541574  6868 net.cpp:408] pool2_p -> pool2_p
I0825 12:15:00.541606  6868 net.cpp:150] Setting up pool2_p
I0825 12:15:00.541612  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.541616  6868 net.cpp:165] Memory required for data: 11929320
I0825 12:15:00.541620  6868 layer_factory.hpp:77] Creating layer norm2_p
I0825 12:15:00.541626  6868 net.cpp:100] Creating Layer norm2_p
I0825 12:15:00.541630  6868 net.cpp:434] norm2_p <- pool2_p
I0825 12:15:00.541640  6868 net.cpp:408] norm2_p -> norm2_p
I0825 12:15:00.541879  6868 net.cpp:150] Setting up norm2_p
I0825 12:15:00.541898  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.541901  6868 net.cpp:165] Memory required for data: 12102376
I0825 12:15:00.541905  6868 layer_factory.hpp:77] Creating layer conv3_p
I0825 12:15:00.541916  6868 net.cpp:100] Creating Layer conv3_p
I0825 12:15:00.541921  6868 net.cpp:434] conv3_p <- norm2_p
I0825 12:15:00.541929  6868 net.cpp:408] conv3_p -> conv3_p
I0825 12:15:00.567257  6868 net.cpp:150] Setting up conv3_p
I0825 12:15:00.567297  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.567301  6868 net.cpp:165] Memory required for data: 12361960
I0825 12:15:00.567312  6868 layer_factory.hpp:77] Creating layer relu3_p
I0825 12:15:00.567323  6868 net.cpp:100] Creating Layer relu3_p
I0825 12:15:00.567329  6868 net.cpp:434] relu3_p <- conv3_p
I0825 12:15:00.567337  6868 net.cpp:395] relu3_p -> conv3_p (in-place)
I0825 12:15:00.567476  6868 net.cpp:150] Setting up relu3_p
I0825 12:15:00.567483  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.567487  6868 net.cpp:165] Memory required for data: 12621544
I0825 12:15:00.567492  6868 layer_factory.hpp:77] Creating layer conv4_p
I0825 12:15:00.567502  6868 net.cpp:100] Creating Layer conv4_p
I0825 12:15:00.567507  6868 net.cpp:434] conv4_p <- conv3_p
I0825 12:15:00.567512  6868 net.cpp:408] conv4_p -> conv4_p
I0825 12:15:00.586849  6868 net.cpp:150] Setting up conv4_p
I0825 12:15:00.586889  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.586894  6868 net.cpp:165] Memory required for data: 12881128
I0825 12:15:00.586910  6868 layer_factory.hpp:77] Creating layer relu4_p
I0825 12:15:00.586921  6868 net.cpp:100] Creating Layer relu4_p
I0825 12:15:00.586927  6868 net.cpp:434] relu4_p <- conv4_p
I0825 12:15:00.586935  6868 net.cpp:395] relu4_p -> conv4_p (in-place)
I0825 12:15:00.587069  6868 net.cpp:150] Setting up relu4_p
I0825 12:15:00.587077  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:00.587080  6868 net.cpp:165] Memory required for data: 13140712
I0825 12:15:00.587085  6868 layer_factory.hpp:77] Creating layer conv5_p
I0825 12:15:00.587096  6868 net.cpp:100] Creating Layer conv5_p
I0825 12:15:00.587100  6868 net.cpp:434] conv5_p <- conv4_p
I0825 12:15:00.587106  6868 net.cpp:408] conv5_p -> conv5_p
I0825 12:15:00.600515  6868 net.cpp:150] Setting up conv5_p
I0825 12:15:00.600553  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.600558  6868 net.cpp:165] Memory required for data: 13313768
I0825 12:15:00.600569  6868 layer_factory.hpp:77] Creating layer relu5_p
I0825 12:15:00.600580  6868 net.cpp:100] Creating Layer relu5_p
I0825 12:15:00.600586  6868 net.cpp:434] relu5_p <- conv5_p
I0825 12:15:00.600594  6868 net.cpp:395] relu5_p -> conv5_p (in-place)
I0825 12:15:00.600831  6868 net.cpp:150] Setting up relu5_p
I0825 12:15:00.600843  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:00.600847  6868 net.cpp:165] Memory required for data: 13486824
I0825 12:15:00.600852  6868 layer_factory.hpp:77] Creating layer pool5_p
I0825 12:15:00.600860  6868 net.cpp:100] Creating Layer pool5_p
I0825 12:15:00.600864  6868 net.cpp:434] pool5_p <- conv5_p
I0825 12:15:00.600872  6868 net.cpp:408] pool5_p -> pool5_p
I0825 12:15:00.600913  6868 net.cpp:150] Setting up pool5_p
I0825 12:15:00.600919  6868 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0825 12:15:00.600922  6868 net.cpp:165] Memory required for data: 13523688
I0825 12:15:00.600927  6868 layer_factory.hpp:77] Creating layer concat
I0825 12:15:00.600939  6868 net.cpp:100] Creating Layer concat
I0825 12:15:00.600944  6868 net.cpp:434] concat <- pool5
I0825 12:15:00.600949  6868 net.cpp:434] concat <- pool5_p
I0825 12:15:00.600953  6868 net.cpp:408] concat -> pool5_concat
I0825 12:15:00.600975  6868 net.cpp:150] Setting up concat
I0825 12:15:00.600980  6868 net.cpp:157] Top shape: 1 512 6 6 (18432)
I0825 12:15:00.600985  6868 net.cpp:165] Memory required for data: 13597416
I0825 12:15:00.600993  6868 layer_factory.hpp:77] Creating layer fc6-new
I0825 12:15:00.601006  6868 net.cpp:100] Creating Layer fc6-new
I0825 12:15:00.601017  6868 net.cpp:434] fc6-new <- pool5_concat
I0825 12:15:00.601024  6868 net.cpp:408] fc6-new -> fc6
I0825 12:15:02.585054  6868 net.cpp:150] Setting up fc6-new
I0825 12:15:02.585109  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:02.585114  6868 net.cpp:165] Memory required for data: 13613800
I0825 12:15:02.585129  6868 layer_factory.hpp:77] Creating layer relu6
I0825 12:15:02.585144  6868 net.cpp:100] Creating Layer relu6
I0825 12:15:02.585152  6868 net.cpp:434] relu6 <- fc6
I0825 12:15:02.585161  6868 net.cpp:395] relu6 -> fc6 (in-place)
I0825 12:15:02.585572  6868 net.cpp:150] Setting up relu6
I0825 12:15:02.585588  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:02.585592  6868 net.cpp:165] Memory required for data: 13630184
I0825 12:15:02.585597  6868 layer_factory.hpp:77] Creating layer drop6
I0825 12:15:02.585609  6868 net.cpp:100] Creating Layer drop6
I0825 12:15:02.585614  6868 net.cpp:434] drop6 <- fc6
I0825 12:15:02.585621  6868 net.cpp:395] drop6 -> fc6 (in-place)
I0825 12:15:02.585657  6868 net.cpp:150] Setting up drop6
I0825 12:15:02.585664  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:02.585666  6868 net.cpp:165] Memory required for data: 13646568
I0825 12:15:02.585669  6868 layer_factory.hpp:77] Creating layer fc7-new
I0825 12:15:02.585678  6868 net.cpp:100] Creating Layer fc7-new
I0825 12:15:02.585682  6868 net.cpp:434] fc7-new <- fc6
I0825 12:15:02.585688  6868 net.cpp:408] fc7-new -> fc7
I0825 12:15:03.023008  6868 net.cpp:150] Setting up fc7-new
I0825 12:15:03.023057  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:03.023063  6868 net.cpp:165] Memory required for data: 13662952
I0825 12:15:03.023075  6868 layer_factory.hpp:77] Creating layer relu7
I0825 12:15:03.023088  6868 net.cpp:100] Creating Layer relu7
I0825 12:15:03.023094  6868 net.cpp:434] relu7 <- fc7
I0825 12:15:03.023102  6868 net.cpp:395] relu7 -> fc7 (in-place)
I0825 12:15:03.023320  6868 net.cpp:150] Setting up relu7
I0825 12:15:03.023332  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:03.023336  6868 net.cpp:165] Memory required for data: 13679336
I0825 12:15:03.023341  6868 layer_factory.hpp:77] Creating layer drop7
I0825 12:15:03.023350  6868 net.cpp:100] Creating Layer drop7
I0825 12:15:03.023355  6868 net.cpp:434] drop7 <- fc7
I0825 12:15:03.023362  6868 net.cpp:395] drop7 -> fc7 (in-place)
I0825 12:15:03.023391  6868 net.cpp:150] Setting up drop7
I0825 12:15:03.023396  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:03.023401  6868 net.cpp:165] Memory required for data: 13695720
I0825 12:15:03.023404  6868 layer_factory.hpp:77] Creating layer fc7-newb
I0825 12:15:03.023413  6868 net.cpp:100] Creating Layer fc7-newb
I0825 12:15:03.023417  6868 net.cpp:434] fc7-newb <- fc7
I0825 12:15:03.023423  6868 net.cpp:408] fc7-newb -> fc7b
I0825 12:15:03.465625  6868 net.cpp:150] Setting up fc7-newb
I0825 12:15:03.465670  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:03.465675  6868 net.cpp:165] Memory required for data: 13712104
I0825 12:15:03.465688  6868 layer_factory.hpp:77] Creating layer relu7b
I0825 12:15:03.465701  6868 net.cpp:100] Creating Layer relu7b
I0825 12:15:03.465708  6868 net.cpp:434] relu7b <- fc7b
I0825 12:15:03.465715  6868 net.cpp:395] relu7b -> fc7b (in-place)
I0825 12:15:03.466112  6868 net.cpp:150] Setting up relu7b
I0825 12:15:03.466127  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:03.466132  6868 net.cpp:165] Memory required for data: 13728488
I0825 12:15:03.466137  6868 layer_factory.hpp:77] Creating layer drop7b
I0825 12:15:03.466145  6868 net.cpp:100] Creating Layer drop7b
I0825 12:15:03.466150  6868 net.cpp:434] drop7b <- fc7b
I0825 12:15:03.466156  6868 net.cpp:395] drop7b -> fc7b (in-place)
I0825 12:15:03.466187  6868 net.cpp:150] Setting up drop7b
I0825 12:15:03.466193  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:03.466197  6868 net.cpp:165] Memory required for data: 13744872
I0825 12:15:03.466208  6868 layer_factory.hpp:77] Creating layer fc8-shapes
I0825 12:15:03.466217  6868 net.cpp:100] Creating Layer fc8-shapes
I0825 12:15:03.466229  6868 net.cpp:434] fc8-shapes <- fc7b
I0825 12:15:03.466235  6868 net.cpp:408] fc8-shapes -> fc8
I0825 12:15:03.467124  6868 net.cpp:150] Setting up fc8-shapes
I0825 12:15:03.467136  6868 net.cpp:157] Top shape: 1 4 (4)
I0825 12:15:03.467140  6868 net.cpp:165] Memory required for data: 13744888
I0825 12:15:03.467147  6868 layer_factory.hpp:77] Creating layer neg
I0825 12:15:03.467156  6868 net.cpp:100] Creating Layer neg
I0825 12:15:03.467161  6868 net.cpp:434] neg <- bbox
I0825 12:15:03.467167  6868 net.cpp:408] neg -> bbox_neg
I0825 12:15:03.467193  6868 net.cpp:150] Setting up neg
I0825 12:15:03.467200  6868 net.cpp:157] Top shape: 1 4 1 1 (4)
I0825 12:15:03.467203  6868 net.cpp:165] Memory required for data: 13744904
I0825 12:15:03.467206  6868 layer_factory.hpp:77] Creating layer flatten
I0825 12:15:03.467218  6868 net.cpp:100] Creating Layer flatten
I0825 12:15:03.467222  6868 net.cpp:434] flatten <- bbox_neg
I0825 12:15:03.467227  6868 net.cpp:408] flatten -> bbox_neg_flat
I0825 12:15:03.467252  6868 net.cpp:150] Setting up flatten
I0825 12:15:03.467260  6868 net.cpp:157] Top shape: 1 4 (4)
I0825 12:15:03.467265  6868 net.cpp:165] Memory required for data: 13744920
I0825 12:15:03.467272  6868 layer_factory.hpp:77] Creating layer subtract
I0825 12:15:03.467279  6868 net.cpp:100] Creating Layer subtract
I0825 12:15:03.467284  6868 net.cpp:434] subtract <- fc8
I0825 12:15:03.467291  6868 net.cpp:434] subtract <- bbox_neg_flat
I0825 12:15:03.467304  6868 net.cpp:408] subtract -> out_diff
I0825 12:15:03.467340  6868 net.cpp:150] Setting up subtract
I0825 12:15:03.467349  6868 net.cpp:157] Top shape: 1 4 (4)
I0825 12:15:03.467351  6868 net.cpp:165] Memory required for data: 13744936
I0825 12:15:03.467355  6868 layer_factory.hpp:77] Creating layer abssum
I0825 12:15:03.467363  6868 net.cpp:100] Creating Layer abssum
I0825 12:15:03.467367  6868 net.cpp:434] abssum <- out_diff
I0825 12:15:03.467372  6868 net.cpp:408] abssum -> loss
I0825 12:15:03.467401  6868 net.cpp:150] Setting up abssum
I0825 12:15:03.467407  6868 net.cpp:157] Top shape: (1)
I0825 12:15:03.467412  6868 net.cpp:160]     with loss weight 1
I0825 12:15:03.467455  6868 net.cpp:165] Memory required for data: 13744940
I0825 12:15:03.467460  6868 net.cpp:226] abssum needs backward computation.
I0825 12:15:03.467464  6868 net.cpp:226] subtract needs backward computation.
I0825 12:15:03.467468  6868 net.cpp:228] flatten does not need backward computation.
I0825 12:15:03.467474  6868 net.cpp:228] neg does not need backward computation.
I0825 12:15:03.467480  6868 net.cpp:226] fc8-shapes needs backward computation.
I0825 12:15:03.467486  6868 net.cpp:226] drop7b needs backward computation.
I0825 12:15:03.467491  6868 net.cpp:226] relu7b needs backward computation.
I0825 12:15:03.467497  6868 net.cpp:226] fc7-newb needs backward computation.
I0825 12:15:03.467507  6868 net.cpp:226] drop7 needs backward computation.
I0825 12:15:03.467512  6868 net.cpp:226] relu7 needs backward computation.
I0825 12:15:03.467515  6868 net.cpp:226] fc7-new needs backward computation.
I0825 12:15:03.467519  6868 net.cpp:226] drop6 needs backward computation.
I0825 12:15:03.467522  6868 net.cpp:226] relu6 needs backward computation.
I0825 12:15:03.467525  6868 net.cpp:226] fc6-new needs backward computation.
I0825 12:15:03.467530  6868 net.cpp:226] concat needs backward computation.
I0825 12:15:03.467535  6868 net.cpp:226] pool5_p needs backward computation.
I0825 12:15:03.467538  6868 net.cpp:226] relu5_p needs backward computation.
I0825 12:15:03.467541  6868 net.cpp:226] conv5_p needs backward computation.
I0825 12:15:03.467545  6868 net.cpp:226] relu4_p needs backward computation.
I0825 12:15:03.467548  6868 net.cpp:226] conv4_p needs backward computation.
I0825 12:15:03.467552  6868 net.cpp:226] relu3_p needs backward computation.
I0825 12:15:03.467555  6868 net.cpp:226] conv3_p needs backward computation.
I0825 12:15:03.467563  6868 net.cpp:226] norm2_p needs backward computation.
I0825 12:15:03.467568  6868 net.cpp:226] pool2_p needs backward computation.
I0825 12:15:03.467579  6868 net.cpp:226] relu2_p needs backward computation.
I0825 12:15:03.467582  6868 net.cpp:226] conv2_p needs backward computation.
I0825 12:15:03.467586  6868 net.cpp:226] norm1_p needs backward computation.
I0825 12:15:03.467591  6868 net.cpp:226] pool1_p needs backward computation.
I0825 12:15:03.467593  6868 net.cpp:226] relu1_p needs backward computation.
I0825 12:15:03.467597  6868 net.cpp:226] conv1_p needs backward computation.
I0825 12:15:03.467602  6868 net.cpp:226] pool5 needs backward computation.
I0825 12:15:03.467605  6868 net.cpp:226] relu5 needs backward computation.
I0825 12:15:03.467609  6868 net.cpp:226] conv5 needs backward computation.
I0825 12:15:03.467613  6868 net.cpp:226] relu4 needs backward computation.
I0825 12:15:03.467617  6868 net.cpp:226] conv4 needs backward computation.
I0825 12:15:03.467620  6868 net.cpp:226] relu3 needs backward computation.
I0825 12:15:03.467623  6868 net.cpp:226] conv3 needs backward computation.
I0825 12:15:03.467628  6868 net.cpp:226] norm2 needs backward computation.
I0825 12:15:03.467631  6868 net.cpp:226] pool2 needs backward computation.
I0825 12:15:03.467635  6868 net.cpp:226] relu2 needs backward computation.
I0825 12:15:03.467638  6868 net.cpp:226] conv2 needs backward computation.
I0825 12:15:03.467643  6868 net.cpp:226] norm1 needs backward computation.
I0825 12:15:03.467646  6868 net.cpp:226] pool1 needs backward computation.
I0825 12:15:03.467649  6868 net.cpp:226] relu1 needs backward computation.
I0825 12:15:03.467653  6868 net.cpp:226] conv1 needs backward computation.
I0825 12:15:03.467658  6868 net.cpp:228] input does not need backward computation.
I0825 12:15:03.467660  6868 net.cpp:270] This network produces output loss
I0825 12:15:03.467687  6868 net.cpp:283] Network initialization done.
I0825 12:15:03.468127  6868 solver.cpp:48] Initializing solver from parameters: 
base_lr: 1e-06
display: 20
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 50000
snapshot_prefix: "nets/models/scratch/solverstate/caffenet_train"
solver_mode: GPU
device_id: 0
random_seed: 800
net: "nets/models/scratch/tracker.prototxt"
I0825 12:15:03.468250  6868 solver.cpp:91] Creating training net from net file: nets/models/scratch/tracker.prototxt
I0825 12:15:03.478904  6868 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: nets/models/scratch/tracker.prototxt
I0825 12:15:03.478955  6868 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0825 12:15:03.478963  6868 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0825 12:15:03.479415  6868 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "input"
  type: "Input"
  top: "target"
  top: "image"
  top: "bbox"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 4
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "target"
  top: "conv1"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "image"
  top: "conv1_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "pool1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "norm1_p"
  top: "conv2_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "pool2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "norm2_p"
  top: "conv3_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "conv5_p"
  type: "Convolution"
  bottom: "conv4_p"
  top: "conv5_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5_p"
  type: "ReLU"
  bottom: "conv5_p"
  top: "conv5_p"
}
layer {
  name: "pool5_p"
  type: "Pooling"
  bottom: "conv5_p"
  top: "pool5_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "pool5"
  bottom: "pool5_p"
  top: "pool5_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc6-new"
  type: "InnerProduct"
  bottom: "pool5_concat"
  top: "fc6"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-newb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc7b"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7b"
  type: "ReLU"
  bottom: "fc7b"
  top: "fc7b"
}
layer {
  name: "drop7b"
  type: "Dropout"
  bottom: "fc7b"
  top: "fc7b"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-shapes"
  type: "InnerProduct"
  bottom: "fc7b"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "neg"
  type: "Power"
  bottom: "bbox"
  top: "bbox_neg"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "bbox_neg"
  top: "bbox_neg_flat"
}
layer {
  name: "subtract"
  type: "Eltwise"
  bottom: "fc8"
  bottom: "bbox_neg_flat"
  top: "out_diff"
}
layer {
  name: "abssum"
  type: "Reduction"
  bottom: "out_diff"
  top: "loss"
  loss_weight: 1
  reduction_param {
    operation: ASUM
  }
}
I0825 12:15:03.479612  6868 layer_factory.hpp:77] Creating layer input
I0825 12:15:03.479632  6868 net.cpp:100] Creating Layer input
I0825 12:15:03.479640  6868 net.cpp:408] input -> target
I0825 12:15:03.479658  6868 net.cpp:408] input -> image
I0825 12:15:03.479673  6868 net.cpp:408] input -> bbox
I0825 12:15:03.479763  6868 net.cpp:150] Setting up input
I0825 12:15:03.479771  6868 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0825 12:15:03.479781  6868 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0825 12:15:03.479785  6868 net.cpp:157] Top shape: 1 4 1 1 (4)
I0825 12:15:03.479789  6868 net.cpp:165] Memory required for data: 1236712
I0825 12:15:03.479794  6868 layer_factory.hpp:77] Creating layer conv1
I0825 12:15:03.479804  6868 net.cpp:100] Creating Layer conv1
I0825 12:15:03.479807  6868 net.cpp:434] conv1 <- target
I0825 12:15:03.479815  6868 net.cpp:408] conv1 -> conv1
I0825 12:15:03.481660  6868 net.cpp:150] Setting up conv1
I0825 12:15:03.481691  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:03.481696  6868 net.cpp:165] Memory required for data: 2398312
I0825 12:15:03.481709  6868 layer_factory.hpp:77] Creating layer relu1
I0825 12:15:03.481720  6868 net.cpp:100] Creating Layer relu1
I0825 12:15:03.481724  6868 net.cpp:434] relu1 <- conv1
I0825 12:15:03.481730  6868 net.cpp:395] relu1 -> conv1 (in-place)
I0825 12:15:03.481866  6868 net.cpp:150] Setting up relu1
I0825 12:15:03.481875  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:03.481878  6868 net.cpp:165] Memory required for data: 3559912
I0825 12:15:03.481883  6868 layer_factory.hpp:77] Creating layer pool1
I0825 12:15:03.481890  6868 net.cpp:100] Creating Layer pool1
I0825 12:15:03.481894  6868 net.cpp:434] pool1 <- conv1
I0825 12:15:03.481899  6868 net.cpp:408] pool1 -> pool1
I0825 12:15:03.481940  6868 net.cpp:150] Setting up pool1
I0825 12:15:03.481946  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:03.481950  6868 net.cpp:165] Memory required for data: 3839848
I0825 12:15:03.481953  6868 layer_factory.hpp:77] Creating layer norm1
I0825 12:15:03.481961  6868 net.cpp:100] Creating Layer norm1
I0825 12:15:03.481966  6868 net.cpp:434] norm1 <- pool1
I0825 12:15:03.481971  6868 net.cpp:408] norm1 -> norm1
I0825 12:15:03.482322  6868 net.cpp:150] Setting up norm1
I0825 12:15:03.482367  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:03.482372  6868 net.cpp:165] Memory required for data: 4119784
I0825 12:15:03.482378  6868 layer_factory.hpp:77] Creating layer conv2
I0825 12:15:03.482421  6868 net.cpp:100] Creating Layer conv2
I0825 12:15:03.482429  6868 net.cpp:434] conv2 <- norm1
I0825 12:15:03.482442  6868 net.cpp:408] conv2 -> conv2
I0825 12:15:03.492377  6868 net.cpp:150] Setting up conv2
I0825 12:15:03.492411  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:03.492416  6868 net.cpp:165] Memory required for data: 4866280
I0825 12:15:03.492429  6868 layer_factory.hpp:77] Creating layer relu2
I0825 12:15:03.492439  6868 net.cpp:100] Creating Layer relu2
I0825 12:15:03.492445  6868 net.cpp:434] relu2 <- conv2
I0825 12:15:03.492452  6868 net.cpp:395] relu2 -> conv2 (in-place)
I0825 12:15:03.492681  6868 net.cpp:150] Setting up relu2
I0825 12:15:03.492691  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:03.492696  6868 net.cpp:165] Memory required for data: 5612776
I0825 12:15:03.492699  6868 layer_factory.hpp:77] Creating layer pool2
I0825 12:15:03.492707  6868 net.cpp:100] Creating Layer pool2
I0825 12:15:03.492712  6868 net.cpp:434] pool2 <- conv2
I0825 12:15:03.492717  6868 net.cpp:408] pool2 -> pool2
I0825 12:15:03.492754  6868 net.cpp:150] Setting up pool2
I0825 12:15:03.492760  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.492764  6868 net.cpp:165] Memory required for data: 5785832
I0825 12:15:03.492768  6868 layer_factory.hpp:77] Creating layer norm2
I0825 12:15:03.492776  6868 net.cpp:100] Creating Layer norm2
I0825 12:15:03.492780  6868 net.cpp:434] norm2 <- pool2
I0825 12:15:03.492786  6868 net.cpp:408] norm2 -> norm2
I0825 12:15:03.492934  6868 net.cpp:150] Setting up norm2
I0825 12:15:03.492944  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.492947  6868 net.cpp:165] Memory required for data: 5958888
I0825 12:15:03.492950  6868 layer_factory.hpp:77] Creating layer conv3
I0825 12:15:03.492969  6868 net.cpp:100] Creating Layer conv3
I0825 12:15:03.492974  6868 net.cpp:434] conv3 <- norm2
I0825 12:15:03.492986  6868 net.cpp:408] conv3 -> conv3
I0825 12:15:03.518903  6868 net.cpp:150] Setting up conv3
I0825 12:15:03.518944  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.518947  6868 net.cpp:165] Memory required for data: 6218472
I0825 12:15:03.518961  6868 layer_factory.hpp:77] Creating layer relu3
I0825 12:15:03.518971  6868 net.cpp:100] Creating Layer relu3
I0825 12:15:03.518977  6868 net.cpp:434] relu3 <- conv3
I0825 12:15:03.518983  6868 net.cpp:395] relu3 -> conv3 (in-place)
I0825 12:15:03.519215  6868 net.cpp:150] Setting up relu3
I0825 12:15:03.519227  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.519232  6868 net.cpp:165] Memory required for data: 6478056
I0825 12:15:03.519235  6868 layer_factory.hpp:77] Creating layer conv4
I0825 12:15:03.519246  6868 net.cpp:100] Creating Layer conv4
I0825 12:15:03.519251  6868 net.cpp:434] conv4 <- conv3
I0825 12:15:03.519258  6868 net.cpp:408] conv4 -> conv4
I0825 12:15:03.537852  6868 net.cpp:150] Setting up conv4
I0825 12:15:03.537892  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.537897  6868 net.cpp:165] Memory required for data: 6737640
I0825 12:15:03.537907  6868 layer_factory.hpp:77] Creating layer relu4
I0825 12:15:03.537917  6868 net.cpp:100] Creating Layer relu4
I0825 12:15:03.537922  6868 net.cpp:434] relu4 <- conv4
I0825 12:15:03.537930  6868 net.cpp:395] relu4 -> conv4 (in-place)
I0825 12:15:03.538161  6868 net.cpp:150] Setting up relu4
I0825 12:15:03.538172  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.538175  6868 net.cpp:165] Memory required for data: 6997224
I0825 12:15:03.538179  6868 layer_factory.hpp:77] Creating layer conv5
I0825 12:15:03.538190  6868 net.cpp:100] Creating Layer conv5
I0825 12:15:03.538194  6868 net.cpp:434] conv5 <- conv4
I0825 12:15:03.538204  6868 net.cpp:408] conv5 -> conv5
I0825 12:15:03.551205  6868 net.cpp:150] Setting up conv5
I0825 12:15:03.551247  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.551251  6868 net.cpp:165] Memory required for data: 7170280
I0825 12:15:03.551265  6868 layer_factory.hpp:77] Creating layer relu5
I0825 12:15:03.551276  6868 net.cpp:100] Creating Layer relu5
I0825 12:15:03.551281  6868 net.cpp:434] relu5 <- conv5
I0825 12:15:03.551288  6868 net.cpp:395] relu5 -> conv5 (in-place)
I0825 12:15:03.551425  6868 net.cpp:150] Setting up relu5
I0825 12:15:03.551434  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.551437  6868 net.cpp:165] Memory required for data: 7343336
I0825 12:15:03.551441  6868 layer_factory.hpp:77] Creating layer pool5
I0825 12:15:03.551448  6868 net.cpp:100] Creating Layer pool5
I0825 12:15:03.551452  6868 net.cpp:434] pool5 <- conv5
I0825 12:15:03.551458  6868 net.cpp:408] pool5 -> pool5
I0825 12:15:03.551497  6868 net.cpp:150] Setting up pool5
I0825 12:15:03.551503  6868 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0825 12:15:03.551507  6868 net.cpp:165] Memory required for data: 7380200
I0825 12:15:03.551511  6868 layer_factory.hpp:77] Creating layer conv1_p
I0825 12:15:03.551523  6868 net.cpp:100] Creating Layer conv1_p
I0825 12:15:03.551527  6868 net.cpp:434] conv1_p <- image
I0825 12:15:03.551533  6868 net.cpp:408] conv1_p -> conv1_p
I0825 12:15:03.553257  6868 net.cpp:150] Setting up conv1_p
I0825 12:15:03.553279  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:03.553283  6868 net.cpp:165] Memory required for data: 8541800
I0825 12:15:03.553292  6868 layer_factory.hpp:77] Creating layer relu1_p
I0825 12:15:03.553299  6868 net.cpp:100] Creating Layer relu1_p
I0825 12:15:03.553304  6868 net.cpp:434] relu1_p <- conv1_p
I0825 12:15:03.553311  6868 net.cpp:395] relu1_p -> conv1_p (in-place)
I0825 12:15:03.553450  6868 net.cpp:150] Setting up relu1_p
I0825 12:15:03.553458  6868 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0825 12:15:03.553462  6868 net.cpp:165] Memory required for data: 9703400
I0825 12:15:03.553467  6868 layer_factory.hpp:77] Creating layer pool1_p
I0825 12:15:03.553478  6868 net.cpp:100] Creating Layer pool1_p
I0825 12:15:03.553483  6868 net.cpp:434] pool1_p <- conv1_p
I0825 12:15:03.553495  6868 net.cpp:408] pool1_p -> pool1_p
I0825 12:15:03.553534  6868 net.cpp:150] Setting up pool1_p
I0825 12:15:03.553539  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:03.553542  6868 net.cpp:165] Memory required for data: 9983336
I0825 12:15:03.553546  6868 layer_factory.hpp:77] Creating layer norm1_p
I0825 12:15:03.553557  6868 net.cpp:100] Creating Layer norm1_p
I0825 12:15:03.553560  6868 net.cpp:434] norm1_p <- pool1_p
I0825 12:15:03.553565  6868 net.cpp:408] norm1_p -> norm1_p
I0825 12:15:03.553822  6868 net.cpp:150] Setting up norm1_p
I0825 12:15:03.553834  6868 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0825 12:15:03.553838  6868 net.cpp:165] Memory required for data: 10263272
I0825 12:15:03.553843  6868 layer_factory.hpp:77] Creating layer conv2_p
I0825 12:15:03.553853  6868 net.cpp:100] Creating Layer conv2_p
I0825 12:15:03.553856  6868 net.cpp:434] conv2_p <- norm1_p
I0825 12:15:03.553863  6868 net.cpp:408] conv2_p -> conv2_p
I0825 12:15:03.563313  6868 net.cpp:150] Setting up conv2_p
I0825 12:15:03.563359  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:03.563364  6868 net.cpp:165] Memory required for data: 11009768
I0825 12:15:03.563374  6868 layer_factory.hpp:77] Creating layer relu2_p
I0825 12:15:03.563386  6868 net.cpp:100] Creating Layer relu2_p
I0825 12:15:03.563391  6868 net.cpp:434] relu2_p <- conv2_p
I0825 12:15:03.563398  6868 net.cpp:395] relu2_p -> conv2_p (in-place)
I0825 12:15:03.563544  6868 net.cpp:150] Setting up relu2_p
I0825 12:15:03.563554  6868 net.cpp:157] Top shape: 1 256 27 27 (186624)
I0825 12:15:03.563556  6868 net.cpp:165] Memory required for data: 11756264
I0825 12:15:03.563560  6868 layer_factory.hpp:77] Creating layer pool2_p
I0825 12:15:03.563568  6868 net.cpp:100] Creating Layer pool2_p
I0825 12:15:03.563572  6868 net.cpp:434] pool2_p <- conv2_p
I0825 12:15:03.563577  6868 net.cpp:408] pool2_p -> pool2_p
I0825 12:15:03.563617  6868 net.cpp:150] Setting up pool2_p
I0825 12:15:03.563623  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.563627  6868 net.cpp:165] Memory required for data: 11929320
I0825 12:15:03.563629  6868 layer_factory.hpp:77] Creating layer norm2_p
I0825 12:15:03.563637  6868 net.cpp:100] Creating Layer norm2_p
I0825 12:15:03.563640  6868 net.cpp:434] norm2_p <- pool2_p
I0825 12:15:03.563645  6868 net.cpp:408] norm2_p -> norm2_p
I0825 12:15:03.563902  6868 net.cpp:150] Setting up norm2_p
I0825 12:15:03.563913  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.563917  6868 net.cpp:165] Memory required for data: 12102376
I0825 12:15:03.563921  6868 layer_factory.hpp:77] Creating layer conv3_p
I0825 12:15:03.563932  6868 net.cpp:100] Creating Layer conv3_p
I0825 12:15:03.563936  6868 net.cpp:434] conv3_p <- norm2_p
I0825 12:15:03.563943  6868 net.cpp:408] conv3_p -> conv3_p
I0825 12:15:03.587954  6868 net.cpp:150] Setting up conv3_p
I0825 12:15:03.587993  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.587997  6868 net.cpp:165] Memory required for data: 12361960
I0825 12:15:03.588007  6868 layer_factory.hpp:77] Creating layer relu3_p
I0825 12:15:03.588018  6868 net.cpp:100] Creating Layer relu3_p
I0825 12:15:03.588024  6868 net.cpp:434] relu3_p <- conv3_p
I0825 12:15:03.588033  6868 net.cpp:395] relu3_p -> conv3_p (in-place)
I0825 12:15:03.588280  6868 net.cpp:150] Setting up relu3_p
I0825 12:15:03.588292  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.588296  6868 net.cpp:165] Memory required for data: 12621544
I0825 12:15:03.588300  6868 layer_factory.hpp:77] Creating layer conv4_p
I0825 12:15:03.588311  6868 net.cpp:100] Creating Layer conv4_p
I0825 12:15:03.588315  6868 net.cpp:434] conv4_p <- conv3_p
I0825 12:15:03.588322  6868 net.cpp:408] conv4_p -> conv4_p
I0825 12:15:03.607060  6868 net.cpp:150] Setting up conv4_p
I0825 12:15:03.607101  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.607112  6868 net.cpp:165] Memory required for data: 12881128
I0825 12:15:03.607127  6868 layer_factory.hpp:77] Creating layer relu4_p
I0825 12:15:03.607146  6868 net.cpp:100] Creating Layer relu4_p
I0825 12:15:03.607151  6868 net.cpp:434] relu4_p <- conv4_p
I0825 12:15:03.607158  6868 net.cpp:395] relu4_p -> conv4_p (in-place)
I0825 12:15:03.607302  6868 net.cpp:150] Setting up relu4_p
I0825 12:15:03.607312  6868 net.cpp:157] Top shape: 1 384 13 13 (64896)
I0825 12:15:03.607316  6868 net.cpp:165] Memory required for data: 13140712
I0825 12:15:03.607319  6868 layer_factory.hpp:77] Creating layer conv5_p
I0825 12:15:03.607331  6868 net.cpp:100] Creating Layer conv5_p
I0825 12:15:03.607333  6868 net.cpp:434] conv5_p <- conv4_p
I0825 12:15:03.607339  6868 net.cpp:408] conv5_p -> conv5_p
I0825 12:15:03.620347  6868 net.cpp:150] Setting up conv5_p
I0825 12:15:03.620384  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.620388  6868 net.cpp:165] Memory required for data: 13313768
I0825 12:15:03.620398  6868 layer_factory.hpp:77] Creating layer relu5_p
I0825 12:15:03.620409  6868 net.cpp:100] Creating Layer relu5_p
I0825 12:15:03.620414  6868 net.cpp:434] relu5_p <- conv5_p
I0825 12:15:03.620422  6868 net.cpp:395] relu5_p -> conv5_p (in-place)
I0825 12:15:03.620563  6868 net.cpp:150] Setting up relu5_p
I0825 12:15:03.620573  6868 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0825 12:15:03.620575  6868 net.cpp:165] Memory required for data: 13486824
I0825 12:15:03.620579  6868 layer_factory.hpp:77] Creating layer pool5_p
I0825 12:15:03.620587  6868 net.cpp:100] Creating Layer pool5_p
I0825 12:15:03.620591  6868 net.cpp:434] pool5_p <- conv5_p
I0825 12:15:03.620596  6868 net.cpp:408] pool5_p -> pool5_p
I0825 12:15:03.620637  6868 net.cpp:150] Setting up pool5_p
I0825 12:15:03.620643  6868 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0825 12:15:03.620647  6868 net.cpp:165] Memory required for data: 13523688
I0825 12:15:03.620651  6868 layer_factory.hpp:77] Creating layer concat
I0825 12:15:03.620656  6868 net.cpp:100] Creating Layer concat
I0825 12:15:03.620661  6868 net.cpp:434] concat <- pool5
I0825 12:15:03.620664  6868 net.cpp:434] concat <- pool5_p
I0825 12:15:03.620671  6868 net.cpp:408] concat -> pool5_concat
I0825 12:15:03.620692  6868 net.cpp:150] Setting up concat
I0825 12:15:03.620697  6868 net.cpp:157] Top shape: 1 512 6 6 (18432)
I0825 12:15:03.620700  6868 net.cpp:165] Memory required for data: 13597416
I0825 12:15:03.620704  6868 layer_factory.hpp:77] Creating layer fc6-new
I0825 12:15:03.620718  6868 net.cpp:100] Creating Layer fc6-new
I0825 12:15:03.620723  6868 net.cpp:434] fc6-new <- pool5_concat
I0825 12:15:03.620728  6868 net.cpp:408] fc6-new -> fc6
I0825 12:15:05.616824  6868 net.cpp:150] Setting up fc6-new
I0825 12:15:05.616876  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:05.616883  6868 net.cpp:165] Memory required for data: 13613800
I0825 12:15:05.616897  6868 layer_factory.hpp:77] Creating layer relu6
I0825 12:15:05.616911  6868 net.cpp:100] Creating Layer relu6
I0825 12:15:05.616919  6868 net.cpp:434] relu6 <- fc6
I0825 12:15:05.616928  6868 net.cpp:395] relu6 -> fc6 (in-place)
I0825 12:15:05.617359  6868 net.cpp:150] Setting up relu6
I0825 12:15:05.617375  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:05.617379  6868 net.cpp:165] Memory required for data: 13630184
I0825 12:15:05.617385  6868 layer_factory.hpp:77] Creating layer drop6
I0825 12:15:05.617393  6868 net.cpp:100] Creating Layer drop6
I0825 12:15:05.617398  6868 net.cpp:434] drop6 <- fc6
I0825 12:15:05.617405  6868 net.cpp:395] drop6 -> fc6 (in-place)
I0825 12:15:05.617437  6868 net.cpp:150] Setting up drop6
I0825 12:15:05.617445  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:05.617449  6868 net.cpp:165] Memory required for data: 13646568
I0825 12:15:05.617454  6868 layer_factory.hpp:77] Creating layer fc7-new
I0825 12:15:05.617463  6868 net.cpp:100] Creating Layer fc7-new
I0825 12:15:05.617467  6868 net.cpp:434] fc7-new <- fc6
I0825 12:15:05.617473  6868 net.cpp:408] fc7-new -> fc7
I0825 12:15:06.059891  6868 net.cpp:150] Setting up fc7-new
I0825 12:15:06.059938  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:06.059944  6868 net.cpp:165] Memory required for data: 13662952
I0825 12:15:06.078200  6868 layer_factory.hpp:77] Creating layer relu7
I0825 12:15:06.078227  6868 net.cpp:100] Creating Layer relu7
I0825 12:15:06.078234  6868 net.cpp:434] relu7 <- fc7
I0825 12:15:06.078243  6868 net.cpp:395] relu7 -> fc7 (in-place)
I0825 12:15:06.078541  6868 net.cpp:150] Setting up relu7
I0825 12:15:06.078555  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:06.078559  6868 net.cpp:165] Memory required for data: 13679336
I0825 12:15:06.078563  6868 layer_factory.hpp:77] Creating layer drop7
I0825 12:15:06.078573  6868 net.cpp:100] Creating Layer drop7
I0825 12:15:06.078578  6868 net.cpp:434] drop7 <- fc7
I0825 12:15:06.078583  6868 net.cpp:395] drop7 -> fc7 (in-place)
I0825 12:15:06.078631  6868 net.cpp:150] Setting up drop7
I0825 12:15:06.078639  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:06.078642  6868 net.cpp:165] Memory required for data: 13695720
I0825 12:15:06.078645  6868 layer_factory.hpp:77] Creating layer fc7-newb
I0825 12:15:06.078655  6868 net.cpp:100] Creating Layer fc7-newb
I0825 12:15:06.078660  6868 net.cpp:434] fc7-newb <- fc7
I0825 12:15:06.078666  6868 net.cpp:408] fc7-newb -> fc7b
I0825 12:15:06.518426  6868 net.cpp:150] Setting up fc7-newb
I0825 12:15:06.518471  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:06.518476  6868 net.cpp:165] Memory required for data: 13712104
I0825 12:15:06.518489  6868 layer_factory.hpp:77] Creating layer relu7b
I0825 12:15:06.518501  6868 net.cpp:100] Creating Layer relu7b
I0825 12:15:06.518508  6868 net.cpp:434] relu7b <- fc7b
I0825 12:15:06.518517  6868 net.cpp:395] relu7b -> fc7b (in-place)
I0825 12:15:06.518934  6868 net.cpp:150] Setting up relu7b
I0825 12:15:06.518951  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:06.518956  6868 net.cpp:165] Memory required for data: 13728488
I0825 12:15:06.518961  6868 layer_factory.hpp:77] Creating layer drop7b
I0825 12:15:06.518970  6868 net.cpp:100] Creating Layer drop7b
I0825 12:15:06.518975  6868 net.cpp:434] drop7b <- fc7b
I0825 12:15:06.518981  6868 net.cpp:395] drop7b -> fc7b (in-place)
I0825 12:15:06.519014  6868 net.cpp:150] Setting up drop7b
I0825 12:15:06.519021  6868 net.cpp:157] Top shape: 1 4096 (4096)
I0825 12:15:06.519026  6868 net.cpp:165] Memory required for data: 13744872
I0825 12:15:06.519029  6868 layer_factory.hpp:77] Creating layer fc8-shapes
I0825 12:15:06.519037  6868 net.cpp:100] Creating Layer fc8-shapes
I0825 12:15:06.519042  6868 net.cpp:434] fc8-shapes <- fc7b
I0825 12:15:06.519048  6868 net.cpp:408] fc8-shapes -> fc8
I0825 12:15:06.519570  6868 net.cpp:150] Setting up fc8-shapes
I0825 12:15:06.519578  6868 net.cpp:157] Top shape: 1 4 (4)
I0825 12:15:06.519582  6868 net.cpp:165] Memory required for data: 13744888
I0825 12:15:06.519588  6868 layer_factory.hpp:77] Creating layer neg
I0825 12:15:06.519598  6868 net.cpp:100] Creating Layer neg
I0825 12:15:06.519601  6868 net.cpp:434] neg <- bbox
I0825 12:15:06.519606  6868 net.cpp:408] neg -> bbox_neg
I0825 12:15:06.519629  6868 net.cpp:150] Setting up neg
I0825 12:15:06.519634  6868 net.cpp:157] Top shape: 1 4 1 1 (4)
I0825 12:15:06.519639  6868 net.cpp:165] Memory required for data: 13744904
I0825 12:15:06.519641  6868 layer_factory.hpp:77] Creating layer flatten
I0825 12:15:06.519646  6868 net.cpp:100] Creating Layer flatten
I0825 12:15:06.519650  6868 net.cpp:434] flatten <- bbox_neg
I0825 12:15:06.519655  6868 net.cpp:408] flatten -> bbox_neg_flat
I0825 12:15:06.519678  6868 net.cpp:150] Setting up flatten
I0825 12:15:06.519683  6868 net.cpp:157] Top shape: 1 4 (4)
I0825 12:15:06.519687  6868 net.cpp:165] Memory required for data: 13744920
I0825 12:15:06.519690  6868 layer_factory.hpp:77] Creating layer subtract
I0825 12:15:06.519695  6868 net.cpp:100] Creating Layer subtract
I0825 12:15:06.519700  6868 net.cpp:434] subtract <- fc8
I0825 12:15:06.519703  6868 net.cpp:434] subtract <- bbox_neg_flat
I0825 12:15:06.519716  6868 net.cpp:408] subtract -> out_diff
I0825 12:15:06.519738  6868 net.cpp:150] Setting up subtract
I0825 12:15:06.519744  6868 net.cpp:157] Top shape: 1 4 (4)
I0825 12:15:06.519757  6868 net.cpp:165] Memory required for data: 13744936
I0825 12:15:06.519759  6868 layer_factory.hpp:77] Creating layer abssum
I0825 12:15:06.519765  6868 net.cpp:100] Creating Layer abssum
I0825 12:15:06.519769  6868 net.cpp:434] abssum <- out_diff
I0825 12:15:06.519774  6868 net.cpp:408] abssum -> loss
I0825 12:15:06.519798  6868 net.cpp:150] Setting up abssum
I0825 12:15:06.519803  6868 net.cpp:157] Top shape: (1)
I0825 12:15:06.519806  6868 net.cpp:160]     with loss weight 1
I0825 12:15:06.519820  6868 net.cpp:165] Memory required for data: 13744940
I0825 12:15:06.519824  6868 net.cpp:226] abssum needs backward computation.
I0825 12:15:06.519829  6868 net.cpp:226] subtract needs backward computation.
I0825 12:15:06.519832  6868 net.cpp:228] flatten does not need backward computation.
I0825 12:15:06.519835  6868 net.cpp:228] neg does not need backward computation.
I0825 12:15:06.519840  6868 net.cpp:226] fc8-shapes needs backward computation.
I0825 12:15:06.519842  6868 net.cpp:226] drop7b needs backward computation.
I0825 12:15:06.519846  6868 net.cpp:226] relu7b needs backward computation.
I0825 12:15:06.519850  6868 net.cpp:226] fc7-newb needs backward computation.
I0825 12:15:06.519853  6868 net.cpp:226] drop7 needs backward computation.
I0825 12:15:06.519856  6868 net.cpp:226] relu7 needs backward computation.
I0825 12:15:06.519860  6868 net.cpp:226] fc7-new needs backward computation.
I0825 12:15:06.519863  6868 net.cpp:226] drop6 needs backward computation.
I0825 12:15:06.519867  6868 net.cpp:226] relu6 needs backward computation.
I0825 12:15:06.519870  6868 net.cpp:226] fc6-new needs backward computation.
I0825 12:15:06.519875  6868 net.cpp:226] concat needs backward computation.
I0825 12:15:06.519878  6868 net.cpp:226] pool5_p needs backward computation.
I0825 12:15:06.519882  6868 net.cpp:226] relu5_p needs backward computation.
I0825 12:15:06.519886  6868 net.cpp:226] conv5_p needs backward computation.
I0825 12:15:06.519889  6868 net.cpp:226] relu4_p needs backward computation.
I0825 12:15:06.519893  6868 net.cpp:226] conv4_p needs backward computation.
I0825 12:15:06.519896  6868 net.cpp:226] relu3_p needs backward computation.
I0825 12:15:06.519901  6868 net.cpp:226] conv3_p needs backward computation.
I0825 12:15:06.519904  6868 net.cpp:226] norm2_p needs backward computation.
I0825 12:15:06.519907  6868 net.cpp:226] pool2_p needs backward computation.
I0825 12:15:06.519912  6868 net.cpp:226] relu2_p needs backward computation.
I0825 12:15:06.519915  6868 net.cpp:226] conv2_p needs backward computation.
I0825 12:15:06.519918  6868 net.cpp:226] norm1_p needs backward computation.
I0825 12:15:06.519922  6868 net.cpp:226] pool1_p needs backward computation.
I0825 12:15:06.519927  6868 net.cpp:226] relu1_p needs backward computation.
I0825 12:15:06.519929  6868 net.cpp:226] conv1_p needs backward computation.
I0825 12:15:06.519933  6868 net.cpp:226] pool5 needs backward computation.
I0825 12:15:06.519937  6868 net.cpp:226] relu5 needs backward computation.
I0825 12:15:06.519940  6868 net.cpp:226] conv5 needs backward computation.
I0825 12:15:06.519945  6868 net.cpp:226] relu4 needs backward computation.
I0825 12:15:06.519948  6868 net.cpp:226] conv4 needs backward computation.
I0825 12:15:06.519953  6868 net.cpp:226] relu3 needs backward computation.
I0825 12:15:06.519956  6868 net.cpp:226] conv3 needs backward computation.
I0825 12:15:06.519959  6868 net.cpp:226] norm2 needs backward computation.
I0825 12:15:06.519963  6868 net.cpp:226] pool2 needs backward computation.
I0825 12:15:06.519968  6868 net.cpp:226] relu2 needs backward computation.
I0825 12:15:06.519971  6868 net.cpp:226] conv2 needs backward computation.
I0825 12:15:06.519974  6868 net.cpp:226] norm1 needs backward computation.
I0825 12:15:06.519979  6868 net.cpp:226] pool1 needs backward computation.
I0825 12:15:06.519981  6868 net.cpp:226] relu1 needs backward computation.
I0825 12:15:06.519989  6868 net.cpp:226] conv1 needs backward computation.
I0825 12:15:06.519992  6868 net.cpp:228] input does not need backward computation.
I0825 12:15:06.520000  6868 net.cpp:270] This network produces output loss
I0825 12:15:06.520020  6868 net.cpp:283] Network initialization done.
I0825 12:15:06.546387  6868 solver.cpp:60] Solver scaffolding done.
