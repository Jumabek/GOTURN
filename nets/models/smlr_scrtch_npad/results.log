I0905 17:39:00.147825  2648 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: nets/models/smlr_scrtch_npad/tracker.prototxt
I0905 17:39:00.148103  2648 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0905 17:39:00.148114  2648 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0905 17:39:00.148473  2648 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "target"
  top: "image"
  top: "bbox"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 4
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "target"
  top: "conv1"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "image"
  top: "conv1_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "pool1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "norm1_p"
  top: "conv2_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "pool2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "norm2_p"
  top: "conv3_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "conv4"
  bottom: "conv4_p"
  top: "conv4_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc6-new"
  type: "InnerProduct"
  bottom: "conv4_concat"
  top: "fc6"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-newb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc7b"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7b"
  type: "ReLU"
  bottom: "fc7b"
  top: "fc7b"
}
layer {
  name: "drop7b"
  type: "Dropout"
  bottom: "fc7b"
  top: "fc7b"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-shapes"
  type: "InnerProduct"
  bottom: "fc7b"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "neg"
  type: "Power"
  bottom: "bbox"
  top: "bbox_neg"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "bbox_neg"
  top: "bbox_neg_flat"
}
layer {
  name: "subtract"
  type: "Eltwise"
  bottom: "fc8"
  bottom: "bbox_neg_flat"
  top: "out_diff"
}
layer {
  name: "abssum"
  type: "Reduction"
  bottom: "out_diff"
  top: "loss"
  loss_weight: 1
  reduction_param {
    operation: ASUM
  }
}
I0905 17:39:00.148612  2648 layer_factory.hpp:77] Creating layer input
I0905 17:39:00.148633  2648 net.cpp:100] Creating Layer input
I0905 17:39:00.148640  2648 net.cpp:408] input -> target
I0905 17:39:00.148677  2648 net.cpp:408] input -> image
I0905 17:39:00.148689  2648 net.cpp:408] input -> bbox
I0905 17:39:00.154711  2648 net.cpp:150] Setting up input
I0905 17:39:00.154755  2648 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0905 17:39:00.154762  2648 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0905 17:39:00.154767  2648 net.cpp:157] Top shape: 1 4 1 1 (4)
I0905 17:39:00.154770  2648 net.cpp:165] Memory required for data: 1236712
I0905 17:39:00.154779  2648 layer_factory.hpp:77] Creating layer conv1
I0905 17:39:00.154808  2648 net.cpp:100] Creating Layer conv1
I0905 17:39:00.154814  2648 net.cpp:434] conv1 <- target
I0905 17:39:00.154826  2648 net.cpp:408] conv1 -> conv1
I0905 17:39:00.272120  2648 net.cpp:150] Setting up conv1
I0905 17:39:00.272161  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:00.272166  2648 net.cpp:165] Memory required for data: 2398312
I0905 17:39:00.272189  2648 layer_factory.hpp:77] Creating layer relu1
I0905 17:39:00.272202  2648 net.cpp:100] Creating Layer relu1
I0905 17:39:00.272208  2648 net.cpp:434] relu1 <- conv1
I0905 17:39:00.272214  2648 net.cpp:395] relu1 -> conv1 (in-place)
I0905 17:39:00.272368  2648 net.cpp:150] Setting up relu1
I0905 17:39:00.272377  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:00.272382  2648 net.cpp:165] Memory required for data: 3559912
I0905 17:39:00.272385  2648 layer_factory.hpp:77] Creating layer pool1
I0905 17:39:00.272393  2648 net.cpp:100] Creating Layer pool1
I0905 17:39:00.272397  2648 net.cpp:434] pool1 <- conv1
I0905 17:39:00.272403  2648 net.cpp:408] pool1 -> pool1
I0905 17:39:00.272445  2648 net.cpp:150] Setting up pool1
I0905 17:39:00.272454  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:00.272456  2648 net.cpp:165] Memory required for data: 3839848
I0905 17:39:00.272460  2648 layer_factory.hpp:77] Creating layer norm1
I0905 17:39:00.272471  2648 net.cpp:100] Creating Layer norm1
I0905 17:39:00.272475  2648 net.cpp:434] norm1 <- pool1
I0905 17:39:00.272480  2648 net.cpp:408] norm1 -> norm1
I0905 17:39:00.272729  2648 net.cpp:150] Setting up norm1
I0905 17:39:00.272742  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:00.272747  2648 net.cpp:165] Memory required for data: 4119784
I0905 17:39:00.272750  2648 layer_factory.hpp:77] Creating layer conv2
I0905 17:39:00.272761  2648 net.cpp:100] Creating Layer conv2
I0905 17:39:00.272765  2648 net.cpp:434] conv2 <- norm1
I0905 17:39:00.272771  2648 net.cpp:408] conv2 -> conv2
I0905 17:39:00.282419  2648 net.cpp:150] Setting up conv2
I0905 17:39:00.282455  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:00.282461  2648 net.cpp:165] Memory required for data: 4661480
I0905 17:39:00.282475  2648 layer_factory.hpp:77] Creating layer relu2
I0905 17:39:00.282486  2648 net.cpp:100] Creating Layer relu2
I0905 17:39:00.282492  2648 net.cpp:434] relu2 <- conv2
I0905 17:39:00.282498  2648 net.cpp:395] relu2 -> conv2 (in-place)
I0905 17:39:00.282641  2648 net.cpp:150] Setting up relu2
I0905 17:39:00.282651  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:00.282655  2648 net.cpp:165] Memory required for data: 5203176
I0905 17:39:00.282660  2648 layer_factory.hpp:77] Creating layer pool2
I0905 17:39:00.282665  2648 net.cpp:100] Creating Layer pool2
I0905 17:39:00.282670  2648 net.cpp:434] pool2 <- conv2
I0905 17:39:00.282675  2648 net.cpp:408] pool2 -> pool2
I0905 17:39:00.282711  2648 net.cpp:150] Setting up pool2
I0905 17:39:00.282716  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:00.282721  2648 net.cpp:165] Memory required for data: 5327080
I0905 17:39:00.282723  2648 layer_factory.hpp:77] Creating layer norm2
I0905 17:39:00.282732  2648 net.cpp:100] Creating Layer norm2
I0905 17:39:00.282737  2648 net.cpp:434] norm2 <- pool2
I0905 17:39:00.282747  2648 net.cpp:408] norm2 -> norm2
I0905 17:39:00.282985  2648 net.cpp:150] Setting up norm2
I0905 17:39:00.282999  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:00.283010  2648 net.cpp:165] Memory required for data: 5450984
I0905 17:39:00.283015  2648 layer_factory.hpp:77] Creating layer conv3
I0905 17:39:00.283025  2648 net.cpp:100] Creating Layer conv3
I0905 17:39:00.283030  2648 net.cpp:434] conv3 <- norm2
I0905 17:39:00.283035  2648 net.cpp:408] conv3 -> conv3
I0905 17:39:00.307447  2648 net.cpp:150] Setting up conv3
I0905 17:39:00.307485  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:00.307492  2648 net.cpp:165] Memory required for data: 5575400
I0905 17:39:00.307507  2648 layer_factory.hpp:77] Creating layer relu3
I0905 17:39:00.307518  2648 net.cpp:100] Creating Layer relu3
I0905 17:39:00.307523  2648 net.cpp:434] relu3 <- conv3
I0905 17:39:00.307528  2648 net.cpp:395] relu3 -> conv3 (in-place)
I0905 17:39:00.307751  2648 net.cpp:150] Setting up relu3
I0905 17:39:00.307763  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:00.307767  2648 net.cpp:165] Memory required for data: 5699816
I0905 17:39:00.307771  2648 layer_factory.hpp:77] Creating layer conv4
I0905 17:39:00.307782  2648 net.cpp:100] Creating Layer conv4
I0905 17:39:00.307786  2648 net.cpp:434] conv4 <- conv3
I0905 17:39:00.307792  2648 net.cpp:408] conv4 -> conv4
I0905 17:39:00.327100  2648 net.cpp:150] Setting up conv4
I0905 17:39:00.327137  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:00.327142  2648 net.cpp:165] Memory required for data: 5775080
I0905 17:39:00.327152  2648 layer_factory.hpp:77] Creating layer relu4
I0905 17:39:00.327162  2648 net.cpp:100] Creating Layer relu4
I0905 17:39:00.327167  2648 net.cpp:434] relu4 <- conv4
I0905 17:39:00.327175  2648 net.cpp:395] relu4 -> conv4 (in-place)
I0905 17:39:00.327309  2648 net.cpp:150] Setting up relu4
I0905 17:39:00.327318  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:00.327322  2648 net.cpp:165] Memory required for data: 5850344
I0905 17:39:00.327327  2648 layer_factory.hpp:77] Creating layer conv1_p
I0905 17:39:00.327337  2648 net.cpp:100] Creating Layer conv1_p
I0905 17:39:00.327342  2648 net.cpp:434] conv1_p <- image
I0905 17:39:00.327348  2648 net.cpp:408] conv1_p -> conv1_p
I0905 17:39:00.329792  2648 net.cpp:150] Setting up conv1_p
I0905 17:39:00.329821  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:00.329826  2648 net.cpp:165] Memory required for data: 7011944
I0905 17:39:00.329839  2648 layer_factory.hpp:77] Creating layer relu1_p
I0905 17:39:00.329850  2648 net.cpp:100] Creating Layer relu1_p
I0905 17:39:00.329855  2648 net.cpp:434] relu1_p <- conv1_p
I0905 17:39:00.329861  2648 net.cpp:395] relu1_p -> conv1_p (in-place)
I0905 17:39:00.329989  2648 net.cpp:150] Setting up relu1_p
I0905 17:39:00.329998  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:00.330000  2648 net.cpp:165] Memory required for data: 8173544
I0905 17:39:00.330004  2648 layer_factory.hpp:77] Creating layer pool1_p
I0905 17:39:00.330011  2648 net.cpp:100] Creating Layer pool1_p
I0905 17:39:00.330015  2648 net.cpp:434] pool1_p <- conv1_p
I0905 17:39:00.330020  2648 net.cpp:408] pool1_p -> pool1_p
I0905 17:39:00.330054  2648 net.cpp:150] Setting up pool1_p
I0905 17:39:00.330060  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:00.330063  2648 net.cpp:165] Memory required for data: 8453480
I0905 17:39:00.330067  2648 layer_factory.hpp:77] Creating layer norm1_p
I0905 17:39:00.330076  2648 net.cpp:100] Creating Layer norm1_p
I0905 17:39:00.330080  2648 net.cpp:434] norm1_p <- pool1_p
I0905 17:39:00.330086  2648 net.cpp:408] norm1_p -> norm1_p
I0905 17:39:00.330412  2648 net.cpp:150] Setting up norm1_p
I0905 17:39:00.330423  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:00.330427  2648 net.cpp:165] Memory required for data: 8733416
I0905 17:39:00.330431  2648 layer_factory.hpp:77] Creating layer conv2_p
I0905 17:39:00.330442  2648 net.cpp:100] Creating Layer conv2_p
I0905 17:39:00.330452  2648 net.cpp:434] conv2_p <- norm1_p
I0905 17:39:00.330459  2648 net.cpp:408] conv2_p -> conv2_p
I0905 17:39:00.341228  2648 net.cpp:150] Setting up conv2_p
I0905 17:39:00.341275  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:00.341281  2648 net.cpp:165] Memory required for data: 9275112
I0905 17:39:00.341291  2648 layer_factory.hpp:77] Creating layer relu2_p
I0905 17:39:00.341301  2648 net.cpp:100] Creating Layer relu2_p
I0905 17:39:00.341307  2648 net.cpp:434] relu2_p <- conv2_p
I0905 17:39:00.341315  2648 net.cpp:395] relu2_p -> conv2_p (in-place)
I0905 17:39:00.341450  2648 net.cpp:150] Setting up relu2_p
I0905 17:39:00.341459  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:00.341464  2648 net.cpp:165] Memory required for data: 9816808
I0905 17:39:00.341467  2648 layer_factory.hpp:77] Creating layer pool2_p
I0905 17:39:00.341475  2648 net.cpp:100] Creating Layer pool2_p
I0905 17:39:00.341480  2648 net.cpp:434] pool2_p <- conv2_p
I0905 17:39:00.341485  2648 net.cpp:408] pool2_p -> pool2_p
I0905 17:39:00.341519  2648 net.cpp:150] Setting up pool2_p
I0905 17:39:00.341526  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:00.341528  2648 net.cpp:165] Memory required for data: 9940712
I0905 17:39:00.341532  2648 layer_factory.hpp:77] Creating layer norm2_p
I0905 17:39:00.341542  2648 net.cpp:100] Creating Layer norm2_p
I0905 17:39:00.341545  2648 net.cpp:434] norm2_p <- pool2_p
I0905 17:39:00.341550  2648 net.cpp:408] norm2_p -> norm2_p
I0905 17:39:00.341789  2648 net.cpp:150] Setting up norm2_p
I0905 17:39:00.341801  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:00.341805  2648 net.cpp:165] Memory required for data: 10064616
I0905 17:39:00.341809  2648 layer_factory.hpp:77] Creating layer conv3_p
I0905 17:39:00.341820  2648 net.cpp:100] Creating Layer conv3_p
I0905 17:39:00.341825  2648 net.cpp:434] conv3_p <- norm2_p
I0905 17:39:00.341830  2648 net.cpp:408] conv3_p -> conv3_p
I0905 17:39:00.366396  2648 net.cpp:150] Setting up conv3_p
I0905 17:39:00.366431  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:00.366436  2648 net.cpp:165] Memory required for data: 10189032
I0905 17:39:00.366446  2648 layer_factory.hpp:77] Creating layer relu3_p
I0905 17:39:00.366456  2648 net.cpp:100] Creating Layer relu3_p
I0905 17:39:00.366461  2648 net.cpp:434] relu3_p <- conv3_p
I0905 17:39:00.366468  2648 net.cpp:395] relu3_p -> conv3_p (in-place)
I0905 17:39:00.366690  2648 net.cpp:150] Setting up relu3_p
I0905 17:39:00.366703  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:00.366705  2648 net.cpp:165] Memory required for data: 10313448
I0905 17:39:00.366710  2648 layer_factory.hpp:77] Creating layer conv4_p
I0905 17:39:00.366720  2648 net.cpp:100] Creating Layer conv4_p
I0905 17:39:00.366725  2648 net.cpp:434] conv4_p <- conv3_p
I0905 17:39:00.366732  2648 net.cpp:408] conv4_p -> conv4_p
I0905 17:39:00.385627  2648 net.cpp:150] Setting up conv4_p
I0905 17:39:00.385666  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:00.385673  2648 net.cpp:165] Memory required for data: 10388712
I0905 17:39:00.385682  2648 layer_factory.hpp:77] Creating layer relu4_p
I0905 17:39:00.385692  2648 net.cpp:100] Creating Layer relu4_p
I0905 17:39:00.385697  2648 net.cpp:434] relu4_p <- conv4_p
I0905 17:39:00.385704  2648 net.cpp:395] relu4_p -> conv4_p (in-place)
I0905 17:39:00.385835  2648 net.cpp:150] Setting up relu4_p
I0905 17:39:00.385843  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:00.385848  2648 net.cpp:165] Memory required for data: 10463976
I0905 17:39:00.385851  2648 layer_factory.hpp:77] Creating layer concat
I0905 17:39:00.385864  2648 net.cpp:100] Creating Layer concat
I0905 17:39:00.385869  2648 net.cpp:434] concat <- conv4
I0905 17:39:00.385874  2648 net.cpp:434] concat <- conv4_p
I0905 17:39:00.385879  2648 net.cpp:408] concat -> conv4_concat
I0905 17:39:00.385905  2648 net.cpp:150] Setting up concat
I0905 17:39:00.385911  2648 net.cpp:157] Top shape: 1 768 7 7 (37632)
I0905 17:39:00.385915  2648 net.cpp:165] Memory required for data: 10614504
I0905 17:39:00.385923  2648 layer_factory.hpp:77] Creating layer fc6-new
I0905 17:39:00.385932  2648 net.cpp:100] Creating Layer fc6-new
I0905 17:39:00.385943  2648 net.cpp:434] fc6-new <- conv4_concat
I0905 17:39:00.385948  2648 net.cpp:408] fc6-new -> fc6
I0905 17:39:04.475822  2648 net.cpp:150] Setting up fc6-new
I0905 17:39:04.475931  2648 net.cpp:157] Top shape: 1 4096 (4096)
I0905 17:39:04.475951  2648 net.cpp:165] Memory required for data: 10630888
I0905 17:39:04.476003  2648 layer_factory.hpp:77] Creating layer relu6
I0905 17:39:04.476037  2648 net.cpp:100] Creating Layer relu6
I0905 17:39:04.476053  2648 net.cpp:434] relu6 <- fc6
I0905 17:39:04.476073  2648 net.cpp:395] relu6 -> fc6 (in-place)
I0905 17:39:04.476948  2648 net.cpp:150] Setting up relu6
I0905 17:39:04.477032  2648 net.cpp:157] Top shape: 1 4096 (4096)
I0905 17:39:04.477041  2648 net.cpp:165] Memory required for data: 10647272
I0905 17:39:04.477048  2648 layer_factory.hpp:77] Creating layer drop6
I0905 17:39:04.477061  2648 net.cpp:100] Creating Layer drop6
I0905 17:39:04.477067  2648 net.cpp:434] drop6 <- fc6
I0905 17:39:04.477075  2648 net.cpp:395] drop6 -> fc6 (in-place)
I0905 17:39:04.477130  2648 net.cpp:150] Setting up drop6
I0905 17:39:04.477140  2648 net.cpp:157] Top shape: 1 4096 (4096)
I0905 17:39:04.477146  2648 net.cpp:165] Memory required for data: 10663656
I0905 17:39:04.477154  2648 layer_factory.hpp:77] Creating layer fc7-new
I0905 17:39:04.477167  2648 net.cpp:100] Creating Layer fc7-new
I0905 17:39:04.477172  2648 net.cpp:434] fc7-new <- fc6
I0905 17:39:04.477180  2648 net.cpp:408] fc7-new -> fc7
I0905 17:39:04.696877  2648 net.cpp:150] Setting up fc7-new
I0905 17:39:04.696916  2648 net.cpp:157] Top shape: 1 2048 (2048)
I0905 17:39:04.696921  2648 net.cpp:165] Memory required for data: 10671848
I0905 17:39:04.696933  2648 layer_factory.hpp:77] Creating layer relu7
I0905 17:39:04.696945  2648 net.cpp:100] Creating Layer relu7
I0905 17:39:04.696950  2648 net.cpp:434] relu7 <- fc7
I0905 17:39:04.696959  2648 net.cpp:395] relu7 -> fc7 (in-place)
I0905 17:39:04.697144  2648 net.cpp:150] Setting up relu7
I0905 17:39:04.697151  2648 net.cpp:157] Top shape: 1 2048 (2048)
I0905 17:39:04.697156  2648 net.cpp:165] Memory required for data: 10680040
I0905 17:39:04.697160  2648 layer_factory.hpp:77] Creating layer drop7
I0905 17:39:04.697167  2648 net.cpp:100] Creating Layer drop7
I0905 17:39:04.697171  2648 net.cpp:434] drop7 <- fc7
I0905 17:39:04.697176  2648 net.cpp:395] drop7 -> fc7 (in-place)
I0905 17:39:04.697199  2648 net.cpp:150] Setting up drop7
I0905 17:39:04.697206  2648 net.cpp:157] Top shape: 1 2048 (2048)
I0905 17:39:04.697208  2648 net.cpp:165] Memory required for data: 10688232
I0905 17:39:04.697212  2648 layer_factory.hpp:77] Creating layer fc7-newb
I0905 17:39:04.697226  2648 net.cpp:100] Creating Layer fc7-newb
I0905 17:39:04.697229  2648 net.cpp:434] fc7-newb <- fc7
I0905 17:39:04.697235  2648 net.cpp:408] fc7-newb -> fc7b
I0905 17:39:04.751344  2648 net.cpp:150] Setting up fc7-newb
I0905 17:39:04.751381  2648 net.cpp:157] Top shape: 1 1024 (1024)
I0905 17:39:04.751386  2648 net.cpp:165] Memory required for data: 10692328
I0905 17:39:04.751399  2648 layer_factory.hpp:77] Creating layer relu7b
I0905 17:39:04.751410  2648 net.cpp:100] Creating Layer relu7b
I0905 17:39:04.751415  2648 net.cpp:434] relu7b <- fc7b
I0905 17:39:04.751422  2648 net.cpp:395] relu7b -> fc7b (in-place)
I0905 17:39:04.751754  2648 net.cpp:150] Setting up relu7b
I0905 17:39:04.751766  2648 net.cpp:157] Top shape: 1 1024 (1024)
I0905 17:39:04.751771  2648 net.cpp:165] Memory required for data: 10696424
I0905 17:39:04.751775  2648 layer_factory.hpp:77] Creating layer drop7b
I0905 17:39:04.751783  2648 net.cpp:100] Creating Layer drop7b
I0905 17:39:04.751788  2648 net.cpp:434] drop7b <- fc7b
I0905 17:39:04.751794  2648 net.cpp:395] drop7b -> fc7b (in-place)
I0905 17:39:04.751817  2648 net.cpp:150] Setting up drop7b
I0905 17:39:04.751823  2648 net.cpp:157] Top shape: 1 1024 (1024)
I0905 17:39:04.751827  2648 net.cpp:165] Memory required for data: 10700520
I0905 17:39:04.751837  2648 layer_factory.hpp:77] Creating layer fc8-shapes
I0905 17:39:04.751845  2648 net.cpp:100] Creating Layer fc8-shapes
I0905 17:39:04.751857  2648 net.cpp:434] fc8-shapes <- fc7b
I0905 17:39:04.751863  2648 net.cpp:408] fc8-shapes -> fc8
I0905 17:39:04.752055  2648 net.cpp:150] Setting up fc8-shapes
I0905 17:39:04.752063  2648 net.cpp:157] Top shape: 1 4 (4)
I0905 17:39:04.752066  2648 net.cpp:165] Memory required for data: 10700536
I0905 17:39:04.752073  2648 layer_factory.hpp:77] Creating layer neg
I0905 17:39:04.752079  2648 net.cpp:100] Creating Layer neg
I0905 17:39:04.752084  2648 net.cpp:434] neg <- bbox
I0905 17:39:04.752087  2648 net.cpp:408] neg -> bbox_neg
I0905 17:39:04.752112  2648 net.cpp:150] Setting up neg
I0905 17:39:04.752118  2648 net.cpp:157] Top shape: 1 4 1 1 (4)
I0905 17:39:04.752122  2648 net.cpp:165] Memory required for data: 10700552
I0905 17:39:04.752125  2648 layer_factory.hpp:77] Creating layer flatten
I0905 17:39:04.752131  2648 net.cpp:100] Creating Layer flatten
I0905 17:39:04.752135  2648 net.cpp:434] flatten <- bbox_neg
I0905 17:39:04.752142  2648 net.cpp:408] flatten -> bbox_neg_flat
I0905 17:39:04.752159  2648 net.cpp:150] Setting up flatten
I0905 17:39:04.752164  2648 net.cpp:157] Top shape: 1 4 (4)
I0905 17:39:04.752167  2648 net.cpp:165] Memory required for data: 10700568
I0905 17:39:04.752171  2648 layer_factory.hpp:77] Creating layer subtract
I0905 17:39:04.752177  2648 net.cpp:100] Creating Layer subtract
I0905 17:39:04.752180  2648 net.cpp:434] subtract <- fc8
I0905 17:39:04.752185  2648 net.cpp:434] subtract <- bbox_neg_flat
I0905 17:39:04.752192  2648 net.cpp:408] subtract -> out_diff
I0905 17:39:04.752208  2648 net.cpp:150] Setting up subtract
I0905 17:39:04.752214  2648 net.cpp:157] Top shape: 1 4 (4)
I0905 17:39:04.752218  2648 net.cpp:165] Memory required for data: 10700584
I0905 17:39:04.752221  2648 layer_factory.hpp:77] Creating layer abssum
I0905 17:39:04.752226  2648 net.cpp:100] Creating Layer abssum
I0905 17:39:04.752230  2648 net.cpp:434] abssum <- out_diff
I0905 17:39:04.752235  2648 net.cpp:408] abssum -> loss
I0905 17:39:04.752254  2648 net.cpp:150] Setting up abssum
I0905 17:39:04.752259  2648 net.cpp:157] Top shape: (1)
I0905 17:39:04.752264  2648 net.cpp:160]     with loss weight 1
I0905 17:39:04.752280  2648 net.cpp:165] Memory required for data: 10700588
I0905 17:39:04.752285  2648 net.cpp:226] abssum needs backward computation.
I0905 17:39:04.752287  2648 net.cpp:226] subtract needs backward computation.
I0905 17:39:04.752291  2648 net.cpp:228] flatten does not need backward computation.
I0905 17:39:04.752295  2648 net.cpp:228] neg does not need backward computation.
I0905 17:39:04.752300  2648 net.cpp:226] fc8-shapes needs backward computation.
I0905 17:39:04.752302  2648 net.cpp:226] drop7b needs backward computation.
I0905 17:39:04.752306  2648 net.cpp:226] relu7b needs backward computation.
I0905 17:39:04.752310  2648 net.cpp:226] fc7-newb needs backward computation.
I0905 17:39:04.752315  2648 net.cpp:226] drop7 needs backward computation.
I0905 17:39:04.752318  2648 net.cpp:226] relu7 needs backward computation.
I0905 17:39:04.752322  2648 net.cpp:226] fc7-new needs backward computation.
I0905 17:39:04.752326  2648 net.cpp:226] drop6 needs backward computation.
I0905 17:39:04.752329  2648 net.cpp:226] relu6 needs backward computation.
I0905 17:39:04.752333  2648 net.cpp:226] fc6-new needs backward computation.
I0905 17:39:04.752337  2648 net.cpp:226] concat needs backward computation.
I0905 17:39:04.752341  2648 net.cpp:226] relu4_p needs backward computation.
I0905 17:39:04.752344  2648 net.cpp:226] conv4_p needs backward computation.
I0905 17:39:04.752348  2648 net.cpp:226] relu3_p needs backward computation.
I0905 17:39:04.752352  2648 net.cpp:226] conv3_p needs backward computation.
I0905 17:39:04.752356  2648 net.cpp:226] norm2_p needs backward computation.
I0905 17:39:04.752359  2648 net.cpp:226] pool2_p needs backward computation.
I0905 17:39:04.752363  2648 net.cpp:226] relu2_p needs backward computation.
I0905 17:39:04.752370  2648 net.cpp:226] conv2_p needs backward computation.
I0905 17:39:04.752374  2648 net.cpp:226] norm1_p needs backward computation.
I0905 17:39:04.752382  2648 net.cpp:226] pool1_p needs backward computation.
I0905 17:39:04.752387  2648 net.cpp:226] relu1_p needs backward computation.
I0905 17:39:04.752390  2648 net.cpp:226] conv1_p needs backward computation.
I0905 17:39:04.752394  2648 net.cpp:226] relu4 needs backward computation.
I0905 17:39:04.752398  2648 net.cpp:226] conv4 needs backward computation.
I0905 17:39:04.752403  2648 net.cpp:226] relu3 needs backward computation.
I0905 17:39:04.752405  2648 net.cpp:226] conv3 needs backward computation.
I0905 17:39:04.752409  2648 net.cpp:226] norm2 needs backward computation.
I0905 17:39:04.752413  2648 net.cpp:226] pool2 needs backward computation.
I0905 17:39:04.752418  2648 net.cpp:226] relu2 needs backward computation.
I0905 17:39:04.752421  2648 net.cpp:226] conv2 needs backward computation.
I0905 17:39:04.752424  2648 net.cpp:226] norm1 needs backward computation.
I0905 17:39:04.752429  2648 net.cpp:226] pool1 needs backward computation.
I0905 17:39:04.752432  2648 net.cpp:226] relu1 needs backward computation.
I0905 17:39:04.752435  2648 net.cpp:226] conv1 needs backward computation.
I0905 17:39:04.752440  2648 net.cpp:228] input does not need backward computation.
I0905 17:39:04.752444  2648 net.cpp:270] This network produces output loss
I0905 17:39:04.752462  2648 net.cpp:283] Network initialization done.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 673685345
I0905 17:39:13.794131  2648 solver.cpp:48] Initializing solver from parameters: 
base_lr: 1e-07
display: 20
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 50000
snapshot_prefix: "nets/models/smlr_scrtch_npad/solverstate/caffenet_train"
solver_mode: GPU
device_id: 0
random_seed: 800
net: "nets/models/smlr_scrtch_npad/tracker.prototxt"
I0905 17:39:13.794246  2648 solver.cpp:91] Creating training net from net file: nets/models/smlr_scrtch_npad/tracker.prototxt
I0905 17:39:13.794788  2648 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: nets/models/smlr_scrtch_npad/tracker.prototxt
I0905 17:39:13.794802  2648 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0905 17:39:13.794806  2648 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0905 17:39:13.795029  2648 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "input"
  type: "Input"
  top: "target"
  top: "image"
  top: "bbox"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 4
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "target"
  top: "conv1"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "image"
  top: "conv1_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "pool1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "norm1_p"
  top: "conv2_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "pool2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "norm2_p"
  top: "conv3_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "conv4"
  bottom: "conv4_p"
  top: "conv4_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc6-new"
  type: "InnerProduct"
  bottom: "conv4_concat"
  top: "fc6"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-newb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc7b"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7b"
  type: "ReLU"
  bottom: "fc7b"
  top: "fc7b"
}
layer {
  name: "drop7b"
  type: "Dropout"
  bottom: "fc7b"
  top: "fc7b"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-shapes"
  type: "InnerProduct"
  bottom: "fc7b"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "neg"
  type: "Power"
  bottom: "bbox"
  top: "bbox_neg"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "bbox_neg"
  top: "bbox_neg_flat"
}
layer {
  name: "subtract"
  type: "Eltwise"
  bottom: "fc8"
  bottom: "bbox_neg_flat"
  top: "out_diff"
}
layer {
  name: "abssum"
  type: "Reduction"
  bottom: "out_diff"
  top: "loss"
  loss_weight: 1
  reduction_param {
    operation: ASUM
  }
}
I0905 17:39:13.795143  2648 layer_factory.hpp:77] Creating layer input
I0905 17:39:13.795156  2648 net.cpp:100] Creating Layer input
I0905 17:39:13.795161  2648 net.cpp:408] input -> target
I0905 17:39:13.795171  2648 net.cpp:408] input -> image
I0905 17:39:13.795179  2648 net.cpp:408] input -> bbox
I0905 17:39:13.795266  2648 net.cpp:150] Setting up input
I0905 17:39:13.795274  2648 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0905 17:39:13.795279  2648 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0905 17:39:13.795284  2648 net.cpp:157] Top shape: 1 4 1 1 (4)
I0905 17:39:13.795287  2648 net.cpp:165] Memory required for data: 1236712
I0905 17:39:13.795291  2648 layer_factory.hpp:77] Creating layer conv1
I0905 17:39:13.795301  2648 net.cpp:100] Creating Layer conv1
I0905 17:39:13.795305  2648 net.cpp:434] conv1 <- target
I0905 17:39:13.795311  2648 net.cpp:408] conv1 -> conv1
I0905 17:39:13.796996  2648 net.cpp:150] Setting up conv1
I0905 17:39:13.797013  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:13.797018  2648 net.cpp:165] Memory required for data: 2398312
I0905 17:39:13.797029  2648 layer_factory.hpp:77] Creating layer relu1
I0905 17:39:13.797036  2648 net.cpp:100] Creating Layer relu1
I0905 17:39:13.797041  2648 net.cpp:434] relu1 <- conv1
I0905 17:39:13.797046  2648 net.cpp:395] relu1 -> conv1 (in-place)
I0905 17:39:13.797267  2648 net.cpp:150] Setting up relu1
I0905 17:39:13.797278  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:13.797288  2648 net.cpp:165] Memory required for data: 3559912
I0905 17:39:13.797292  2648 layer_factory.hpp:77] Creating layer pool1
I0905 17:39:13.797299  2648 net.cpp:100] Creating Layer pool1
I0905 17:39:13.797304  2648 net.cpp:434] pool1 <- conv1
I0905 17:39:13.797309  2648 net.cpp:408] pool1 -> pool1
I0905 17:39:13.797346  2648 net.cpp:150] Setting up pool1
I0905 17:39:13.797353  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:13.797358  2648 net.cpp:165] Memory required for data: 3839848
I0905 17:39:13.797360  2648 layer_factory.hpp:77] Creating layer norm1
I0905 17:39:13.797369  2648 net.cpp:100] Creating Layer norm1
I0905 17:39:13.797379  2648 net.cpp:434] norm1 <- pool1
I0905 17:39:13.797384  2648 net.cpp:408] norm1 -> norm1
I0905 17:39:13.797627  2648 net.cpp:150] Setting up norm1
I0905 17:39:13.797638  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:13.797642  2648 net.cpp:165] Memory required for data: 4119784
I0905 17:39:13.797646  2648 layer_factory.hpp:77] Creating layer conv2
I0905 17:39:13.797655  2648 net.cpp:100] Creating Layer conv2
I0905 17:39:13.797659  2648 net.cpp:434] conv2 <- norm1
I0905 17:39:13.797665  2648 net.cpp:408] conv2 -> conv2
I0905 17:39:13.807020  2648 net.cpp:150] Setting up conv2
I0905 17:39:13.807051  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:13.807056  2648 net.cpp:165] Memory required for data: 4661480
I0905 17:39:13.807070  2648 layer_factory.hpp:77] Creating layer relu2
I0905 17:39:13.807080  2648 net.cpp:100] Creating Layer relu2
I0905 17:39:13.807085  2648 net.cpp:434] relu2 <- conv2
I0905 17:39:13.807091  2648 net.cpp:395] relu2 -> conv2 (in-place)
I0905 17:39:13.807323  2648 net.cpp:150] Setting up relu2
I0905 17:39:13.807335  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:13.807339  2648 net.cpp:165] Memory required for data: 5203176
I0905 17:39:13.807343  2648 layer_factory.hpp:77] Creating layer pool2
I0905 17:39:13.807349  2648 net.cpp:100] Creating Layer pool2
I0905 17:39:13.807353  2648 net.cpp:434] pool2 <- conv2
I0905 17:39:13.807359  2648 net.cpp:408] pool2 -> pool2
I0905 17:39:13.807396  2648 net.cpp:150] Setting up pool2
I0905 17:39:13.807402  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:13.807405  2648 net.cpp:165] Memory required for data: 5327080
I0905 17:39:13.807410  2648 layer_factory.hpp:77] Creating layer norm2
I0905 17:39:13.807418  2648 net.cpp:100] Creating Layer norm2
I0905 17:39:13.807422  2648 net.cpp:434] norm2 <- pool2
I0905 17:39:13.807428  2648 net.cpp:408] norm2 -> norm2
I0905 17:39:13.807579  2648 net.cpp:150] Setting up norm2
I0905 17:39:13.807588  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:13.807592  2648 net.cpp:165] Memory required for data: 5450984
I0905 17:39:13.807595  2648 layer_factory.hpp:77] Creating layer conv3
I0905 17:39:13.807607  2648 net.cpp:100] Creating Layer conv3
I0905 17:39:13.807612  2648 net.cpp:434] conv3 <- norm2
I0905 17:39:13.807617  2648 net.cpp:408] conv3 -> conv3
I0905 17:39:13.834131  2648 net.cpp:150] Setting up conv3
I0905 17:39:13.834169  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:13.834174  2648 net.cpp:165] Memory required for data: 5575400
I0905 17:39:13.834188  2648 layer_factory.hpp:77] Creating layer relu3
I0905 17:39:13.834200  2648 net.cpp:100] Creating Layer relu3
I0905 17:39:13.834205  2648 net.cpp:434] relu3 <- conv3
I0905 17:39:13.834213  2648 net.cpp:395] relu3 -> conv3 (in-place)
I0905 17:39:13.834441  2648 net.cpp:150] Setting up relu3
I0905 17:39:13.834453  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:13.834456  2648 net.cpp:165] Memory required for data: 5699816
I0905 17:39:13.834460  2648 layer_factory.hpp:77] Creating layer conv4
I0905 17:39:13.834472  2648 net.cpp:100] Creating Layer conv4
I0905 17:39:13.834476  2648 net.cpp:434] conv4 <- conv3
I0905 17:39:13.834483  2648 net.cpp:408] conv4 -> conv4
I0905 17:39:13.854511  2648 net.cpp:150] Setting up conv4
I0905 17:39:13.854552  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:13.854558  2648 net.cpp:165] Memory required for data: 5775080
I0905 17:39:13.854573  2648 layer_factory.hpp:77] Creating layer relu4
I0905 17:39:13.854583  2648 net.cpp:100] Creating Layer relu4
I0905 17:39:13.854589  2648 net.cpp:434] relu4 <- conv4
I0905 17:39:13.854596  2648 net.cpp:395] relu4 -> conv4 (in-place)
I0905 17:39:13.854825  2648 net.cpp:150] Setting up relu4
I0905 17:39:13.854836  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:13.854840  2648 net.cpp:165] Memory required for data: 5850344
I0905 17:39:13.854845  2648 layer_factory.hpp:77] Creating layer conv1_p
I0905 17:39:13.854856  2648 net.cpp:100] Creating Layer conv1_p
I0905 17:39:13.854866  2648 net.cpp:434] conv1_p <- image
I0905 17:39:13.854873  2648 net.cpp:408] conv1_p -> conv1_p
I0905 17:39:13.856462  2648 net.cpp:150] Setting up conv1_p
I0905 17:39:13.856477  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:13.856480  2648 net.cpp:165] Memory required for data: 7011944
I0905 17:39:13.856490  2648 layer_factory.hpp:77] Creating layer relu1_p
I0905 17:39:13.856498  2648 net.cpp:100] Creating Layer relu1_p
I0905 17:39:13.856503  2648 net.cpp:434] relu1_p <- conv1_p
I0905 17:39:13.856508  2648 net.cpp:395] relu1_p -> conv1_p (in-place)
I0905 17:39:13.856729  2648 net.cpp:150] Setting up relu1_p
I0905 17:39:13.856740  2648 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0905 17:39:13.856745  2648 net.cpp:165] Memory required for data: 8173544
I0905 17:39:13.856748  2648 layer_factory.hpp:77] Creating layer pool1_p
I0905 17:39:13.856756  2648 net.cpp:100] Creating Layer pool1_p
I0905 17:39:13.856760  2648 net.cpp:434] pool1_p <- conv1_p
I0905 17:39:13.856765  2648 net.cpp:408] pool1_p -> pool1_p
I0905 17:39:13.856802  2648 net.cpp:150] Setting up pool1_p
I0905 17:39:13.856808  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:13.856812  2648 net.cpp:165] Memory required for data: 8453480
I0905 17:39:13.856817  2648 layer_factory.hpp:77] Creating layer norm1_p
I0905 17:39:13.856830  2648 net.cpp:100] Creating Layer norm1_p
I0905 17:39:13.856837  2648 net.cpp:434] norm1_p <- pool1_p
I0905 17:39:13.856844  2648 net.cpp:408] norm1_p -> norm1_p
I0905 17:39:13.857177  2648 net.cpp:150] Setting up norm1_p
I0905 17:39:13.857218  2648 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0905 17:39:13.857223  2648 net.cpp:165] Memory required for data: 8733416
I0905 17:39:13.857229  2648 layer_factory.hpp:77] Creating layer conv2_p
I0905 17:39:13.857262  2648 net.cpp:100] Creating Layer conv2_p
I0905 17:39:13.857271  2648 net.cpp:434] conv2_p <- norm1_p
I0905 17:39:13.857285  2648 net.cpp:408] conv2_p -> conv2_p
I0905 17:39:13.868877  2648 net.cpp:150] Setting up conv2_p
I0905 17:39:13.868924  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:13.868929  2648 net.cpp:165] Memory required for data: 9275112
I0905 17:39:13.868940  2648 layer_factory.hpp:77] Creating layer relu2_p
I0905 17:39:13.868952  2648 net.cpp:100] Creating Layer relu2_p
I0905 17:39:13.868957  2648 net.cpp:434] relu2_p <- conv2_p
I0905 17:39:13.868965  2648 net.cpp:395] relu2_p -> conv2_p (in-place)
I0905 17:39:13.869251  2648 net.cpp:150] Setting up relu2_p
I0905 17:39:13.869264  2648 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0905 17:39:13.869268  2648 net.cpp:165] Memory required for data: 9816808
I0905 17:39:13.869273  2648 layer_factory.hpp:77] Creating layer pool2_p
I0905 17:39:13.869282  2648 net.cpp:100] Creating Layer pool2_p
I0905 17:39:13.869285  2648 net.cpp:434] pool2_p <- conv2_p
I0905 17:39:13.869293  2648 net.cpp:408] pool2_p -> pool2_p
I0905 17:39:13.869349  2648 net.cpp:150] Setting up pool2_p
I0905 17:39:13.869354  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:13.869357  2648 net.cpp:165] Memory required for data: 9940712
I0905 17:39:13.869361  2648 layer_factory.hpp:77] Creating layer norm2_p
I0905 17:39:13.869369  2648 net.cpp:100] Creating Layer norm2_p
I0905 17:39:13.869374  2648 net.cpp:434] norm2_p <- pool2_p
I0905 17:39:13.869379  2648 net.cpp:408] norm2_p -> norm2_p
I0905 17:39:13.869549  2648 net.cpp:150] Setting up norm2_p
I0905 17:39:13.869565  2648 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0905 17:39:13.869570  2648 net.cpp:165] Memory required for data: 10064616
I0905 17:39:13.869573  2648 layer_factory.hpp:77] Creating layer conv3_p
I0905 17:39:13.869585  2648 net.cpp:100] Creating Layer conv3_p
I0905 17:39:13.869590  2648 net.cpp:434] conv3_p <- norm2_p
I0905 17:39:13.869596  2648 net.cpp:408] conv3_p -> conv3_p
I0905 17:39:13.893493  2648 net.cpp:150] Setting up conv3_p
I0905 17:39:13.893529  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:13.893534  2648 net.cpp:165] Memory required for data: 10189032
I0905 17:39:13.893553  2648 layer_factory.hpp:77] Creating layer relu3_p
I0905 17:39:13.893565  2648 net.cpp:100] Creating Layer relu3_p
I0905 17:39:13.893571  2648 net.cpp:434] relu3_p <- conv3_p
I0905 17:39:13.893578  2648 net.cpp:395] relu3_p -> conv3_p (in-place)
I0905 17:39:13.893805  2648 net.cpp:150] Setting up relu3_p
I0905 17:39:13.893816  2648 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0905 17:39:13.893821  2648 net.cpp:165] Memory required for data: 10313448
I0905 17:39:13.893824  2648 layer_factory.hpp:77] Creating layer conv4_p
I0905 17:39:13.893836  2648 net.cpp:100] Creating Layer conv4_p
I0905 17:39:13.893841  2648 net.cpp:434] conv4_p <- conv3_p
I0905 17:39:13.893846  2648 net.cpp:408] conv4_p -> conv4_p
I0905 17:39:13.912520  2648 net.cpp:150] Setting up conv4_p
I0905 17:39:13.912556  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:13.912562  2648 net.cpp:165] Memory required for data: 10388712
I0905 17:39:13.912572  2648 layer_factory.hpp:77] Creating layer relu4_p
I0905 17:39:13.912581  2648 net.cpp:100] Creating Layer relu4_p
I0905 17:39:13.912587  2648 net.cpp:434] relu4_p <- conv4_p
I0905 17:39:13.912595  2648 net.cpp:395] relu4_p -> conv4_p (in-place)
I0905 17:39:13.912828  2648 net.cpp:150] Setting up relu4_p
I0905 17:39:13.912839  2648 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0905 17:39:13.912843  2648 net.cpp:165] Memory required for data: 10463976
I0905 17:39:13.912847  2648 layer_factory.hpp:77] Creating layer concat
I0905 17:39:13.912854  2648 net.cpp:100] Creating Layer concat
I0905 17:39:13.912859  2648 net.cpp:434] concat <- conv4
I0905 17:39:13.912864  2648 net.cpp:434] concat <- conv4_p
I0905 17:39:13.912870  2648 net.cpp:408] concat -> conv4_concat
I0905 17:39:13.912899  2648 net.cpp:150] Setting up concat
I0905 17:39:13.912905  2648 net.cpp:157] Top shape: 1 768 7 7 (37632)
I0905 17:39:13.912909  2648 net.cpp:165] Memory required for data: 10614504
I0905 17:39:13.912912  2648 layer_factory.hpp:77] Creating layer fc6-new
I0905 17:39:13.912919  2648 net.cpp:100] Creating Layer fc6-new
I0905 17:39:13.912924  2648 net.cpp:434] fc6-new <- conv4_concat
I0905 17:39:13.912930  2648 net.cpp:408] fc6-new -> fc6
I0905 17:39:18.249874  2648 net.cpp:150] Setting up fc6-new
I0905 17:39:18.249914  2648 net.cpp:157] Top shape: 1 4096 (4096)
I0905 17:39:18.249919  2648 net.cpp:165] Memory required for data: 10630888
I0905 17:39:18.249936  2648 layer_factory.hpp:77] Creating layer relu6
I0905 17:39:18.249948  2648 net.cpp:100] Creating Layer relu6
I0905 17:39:18.249953  2648 net.cpp:434] relu6 <- fc6
I0905 17:39:18.249958  2648 net.cpp:395] relu6 -> fc6 (in-place)
I0905 17:39:18.250149  2648 net.cpp:150] Setting up relu6
I0905 17:39:18.250157  2648 net.cpp:157] Top shape: 1 4096 (4096)
I0905 17:39:18.250160  2648 net.cpp:165] Memory required for data: 10647272
I0905 17:39:18.250164  2648 layer_factory.hpp:77] Creating layer drop6
I0905 17:39:18.250171  2648 net.cpp:100] Creating Layer drop6
I0905 17:39:18.250175  2648 net.cpp:434] drop6 <- fc6
I0905 17:39:18.250180  2648 net.cpp:395] drop6 -> fc6 (in-place)
I0905 17:39:18.250203  2648 net.cpp:150] Setting up drop6
I0905 17:39:18.250210  2648 net.cpp:157] Top shape: 1 4096 (4096)
I0905 17:39:18.250212  2648 net.cpp:165] Memory required for data: 10663656
I0905 17:39:18.250216  2648 layer_factory.hpp:77] Creating layer fc7-new
I0905 17:39:18.250224  2648 net.cpp:100] Creating Layer fc7-new
I0905 17:39:18.250228  2648 net.cpp:434] fc7-new <- fc6
I0905 17:39:18.250241  2648 net.cpp:408] fc7-new -> fc7
I0905 17:39:18.482874  2648 net.cpp:150] Setting up fc7-new
I0905 17:39:18.482915  2648 net.cpp:157] Top shape: 1 2048 (2048)
I0905 17:39:18.482920  2648 net.cpp:165] Memory required for data: 10671848
I0905 17:39:18.482930  2648 layer_factory.hpp:77] Creating layer relu7
I0905 17:39:18.482941  2648 net.cpp:100] Creating Layer relu7
I0905 17:39:18.482946  2648 net.cpp:434] relu7 <- fc7
I0905 17:39:18.482952  2648 net.cpp:395] relu7 -> fc7 (in-place)
I0905 17:39:18.483297  2648 net.cpp:150] Setting up relu7
I0905 17:39:18.483309  2648 net.cpp:157] Top shape: 1 2048 (2048)
I0905 17:39:18.483324  2648 net.cpp:165] Memory required for data: 10680040
I0905 17:39:18.483327  2648 layer_factory.hpp:77] Creating layer drop7
I0905 17:39:18.483335  2648 net.cpp:100] Creating Layer drop7
I0905 17:39:18.483340  2648 net.cpp:434] drop7 <- fc7
I0905 17:39:18.483346  2648 net.cpp:395] drop7 -> fc7 (in-place)
I0905 17:39:18.483371  2648 net.cpp:150] Setting up drop7
I0905 17:39:18.483378  2648 net.cpp:157] Top shape: 1 2048 (2048)
I0905 17:39:18.483382  2648 net.cpp:165] Memory required for data: 10688232
I0905 17:39:18.483386  2648 layer_factory.hpp:77] Creating layer fc7-newb
I0905 17:39:18.483397  2648 net.cpp:100] Creating Layer fc7-newb
I0905 17:39:18.483402  2648 net.cpp:434] fc7-newb <- fc7
I0905 17:39:18.483407  2648 net.cpp:408] fc7-newb -> fc7b
I0905 17:39:18.542278  2648 net.cpp:150] Setting up fc7-newb
I0905 17:39:18.542315  2648 net.cpp:157] Top shape: 1 1024 (1024)
I0905 17:39:18.542318  2648 net.cpp:165] Memory required for data: 10692328
I0905 17:39:18.542330  2648 layer_factory.hpp:77] Creating layer relu7b
I0905 17:39:18.542342  2648 net.cpp:100] Creating Layer relu7b
I0905 17:39:18.542348  2648 net.cpp:434] relu7b <- fc7b
I0905 17:39:18.542354  2648 net.cpp:395] relu7b -> fc7b (in-place)
I0905 17:39:18.542546  2648 net.cpp:150] Setting up relu7b
I0905 17:39:18.542556  2648 net.cpp:157] Top shape: 1 1024 (1024)
I0905 17:39:18.542558  2648 net.cpp:165] Memory required for data: 10696424
I0905 17:39:18.542562  2648 layer_factory.hpp:77] Creating layer drop7b
I0905 17:39:18.542569  2648 net.cpp:100] Creating Layer drop7b
I0905 17:39:18.542573  2648 net.cpp:434] drop7b <- fc7b
I0905 17:39:18.542578  2648 net.cpp:395] drop7b -> fc7b (in-place)
I0905 17:39:18.542603  2648 net.cpp:150] Setting up drop7b
I0905 17:39:18.542609  2648 net.cpp:157] Top shape: 1 1024 (1024)
I0905 17:39:18.542613  2648 net.cpp:165] Memory required for data: 10700520
I0905 17:39:18.542615  2648 layer_factory.hpp:77] Creating layer fc8-shapes
I0905 17:39:18.542624  2648 net.cpp:100] Creating Layer fc8-shapes
I0905 17:39:18.542629  2648 net.cpp:434] fc8-shapes <- fc7b
I0905 17:39:18.542634  2648 net.cpp:408] fc8-shapes -> fc8
I0905 17:39:18.542834  2648 net.cpp:150] Setting up fc8-shapes
I0905 17:39:18.542840  2648 net.cpp:157] Top shape: 1 4 (4)
I0905 17:39:18.542843  2648 net.cpp:165] Memory required for data: 10700536
I0905 17:39:18.542850  2648 layer_factory.hpp:77] Creating layer neg
I0905 17:39:18.542855  2648 net.cpp:100] Creating Layer neg
I0905 17:39:18.542860  2648 net.cpp:434] neg <- bbox
I0905 17:39:18.542865  2648 net.cpp:408] neg -> bbox_neg
I0905 17:39:18.542884  2648 net.cpp:150] Setting up neg
I0905 17:39:18.542889  2648 net.cpp:157] Top shape: 1 4 1 1 (4)
I0905 17:39:18.542893  2648 net.cpp:165] Memory required for data: 10700552
I0905 17:39:18.542896  2648 layer_factory.hpp:77] Creating layer flatten
I0905 17:39:18.542903  2648 net.cpp:100] Creating Layer flatten
I0905 17:39:18.542906  2648 net.cpp:434] flatten <- bbox_neg
I0905 17:39:18.542912  2648 net.cpp:408] flatten -> bbox_neg_flat
I0905 17:39:18.542930  2648 net.cpp:150] Setting up flatten
I0905 17:39:18.542937  2648 net.cpp:157] Top shape: 1 4 (4)
I0905 17:39:18.542939  2648 net.cpp:165] Memory required for data: 10700568
I0905 17:39:18.542943  2648 layer_factory.hpp:77] Creating layer subtract
I0905 17:39:18.542948  2648 net.cpp:100] Creating Layer subtract
I0905 17:39:18.542951  2648 net.cpp:434] subtract <- fc8
I0905 17:39:18.542963  2648 net.cpp:434] subtract <- bbox_neg_flat
I0905 17:39:18.542968  2648 net.cpp:408] subtract -> out_diff
I0905 17:39:18.542987  2648 net.cpp:150] Setting up subtract
I0905 17:39:18.542992  2648 net.cpp:157] Top shape: 1 4 (4)
I0905 17:39:18.542995  2648 net.cpp:165] Memory required for data: 10700584
I0905 17:39:18.542999  2648 layer_factory.hpp:77] Creating layer abssum
I0905 17:39:18.543005  2648 net.cpp:100] Creating Layer abssum
I0905 17:39:18.543009  2648 net.cpp:434] abssum <- out_diff
I0905 17:39:18.543015  2648 net.cpp:408] abssum -> loss
I0905 17:39:18.543033  2648 net.cpp:150] Setting up abssum
I0905 17:39:18.543045  2648 net.cpp:157] Top shape: (1)
I0905 17:39:18.543048  2648 net.cpp:160]     with loss weight 1
I0905 17:39:18.543057  2648 net.cpp:165] Memory required for data: 10700588
I0905 17:39:18.543061  2648 net.cpp:226] abssum needs backward computation.
I0905 17:39:18.543066  2648 net.cpp:226] subtract needs backward computation.
I0905 17:39:18.543069  2648 net.cpp:228] flatten does not need backward computation.
I0905 17:39:18.543072  2648 net.cpp:228] neg does not need backward computation.
I0905 17:39:18.543076  2648 net.cpp:226] fc8-shapes needs backward computation.
I0905 17:39:18.543081  2648 net.cpp:226] drop7b needs backward computation.
I0905 17:39:18.543083  2648 net.cpp:226] relu7b needs backward computation.
I0905 17:39:18.543087  2648 net.cpp:226] fc7-newb needs backward computation.
I0905 17:39:18.543090  2648 net.cpp:226] drop7 needs backward computation.
I0905 17:39:18.543094  2648 net.cpp:226] relu7 needs backward computation.
I0905 17:39:18.543097  2648 net.cpp:226] fc7-new needs backward computation.
I0905 17:39:18.543102  2648 net.cpp:226] drop6 needs backward computation.
I0905 17:39:18.543105  2648 net.cpp:226] relu6 needs backward computation.
I0905 17:39:18.543108  2648 net.cpp:226] fc6-new needs backward computation.
I0905 17:39:18.543112  2648 net.cpp:226] concat needs backward computation.
I0905 17:39:18.543117  2648 net.cpp:226] relu4_p needs backward computation.
I0905 17:39:18.543120  2648 net.cpp:226] conv4_p needs backward computation.
I0905 17:39:18.543124  2648 net.cpp:226] relu3_p needs backward computation.
I0905 17:39:18.543128  2648 net.cpp:226] conv3_p needs backward computation.
I0905 17:39:18.543131  2648 net.cpp:226] norm2_p needs backward computation.
I0905 17:39:18.543135  2648 net.cpp:226] pool2_p needs backward computation.
I0905 17:39:18.543139  2648 net.cpp:226] relu2_p needs backward computation.
I0905 17:39:18.543143  2648 net.cpp:226] conv2_p needs backward computation.
I0905 17:39:18.543146  2648 net.cpp:226] norm1_p needs backward computation.
I0905 17:39:18.543150  2648 net.cpp:226] pool1_p needs backward computation.
I0905 17:39:18.543154  2648 net.cpp:226] relu1_p needs backward computation.
I0905 17:39:18.543157  2648 net.cpp:226] conv1_p needs backward computation.
I0905 17:39:18.543161  2648 net.cpp:226] relu4 needs backward computation.
I0905 17:39:18.543165  2648 net.cpp:226] conv4 needs backward computation.
I0905 17:39:18.543169  2648 net.cpp:226] relu3 needs backward computation.
I0905 17:39:18.543174  2648 net.cpp:226] conv3 needs backward computation.
I0905 17:39:18.543176  2648 net.cpp:226] norm2 needs backward computation.
I0905 17:39:18.543180  2648 net.cpp:226] pool2 needs backward computation.
I0905 17:39:18.543184  2648 net.cpp:226] relu2 needs backward computation.
I0905 17:39:18.543189  2648 net.cpp:226] conv2 needs backward computation.
I0905 17:39:18.543191  2648 net.cpp:226] norm1 needs backward computation.
I0905 17:39:18.543195  2648 net.cpp:226] pool1 needs backward computation.
I0905 17:39:18.543200  2648 net.cpp:226] relu1 needs backward computation.
I0905 17:39:18.543203  2648 net.cpp:226] conv1 needs backward computation.
I0905 17:39:18.543207  2648 net.cpp:228] input does not need backward computation.
I0905 17:39:18.543210  2648 net.cpp:270] This network produces output loss
I0905 17:39:18.543228  2648 net.cpp:283] Network initialization done.
I0905 17:39:18.543324  2648 solver.cpp:60] Solver scaffolding done.
