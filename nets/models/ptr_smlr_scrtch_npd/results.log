I0912 21:17:13.499222  2840 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: nets/models/ptr_smlr_scrtch_npd/tracker.prototxt
I0912 21:17:13.499392  2840 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0912 21:17:13.499402  2840 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0912 21:17:13.499694  2840 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "target"
  top: "image"
  top: "bbox"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 1
      dim: 4
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "target"
  top: "conv1"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "image"
  top: "conv1_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "pool1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "norm1_p"
  top: "conv2_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "pool2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "norm2_p"
  top: "conv3_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "conv4"
  bottom: "conv4_p"
  top: "conv4_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc6-new"
  type: "InnerProduct"
  bottom: "conv4_concat"
  top: "fc6"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-newb"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc7b"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7b"
  type: "ReLU"
  bottom: "fc7b"
  top: "fc7b"
}
layer {
  name: "drop7b"
  type: "Dropout"
  bottom: "fc7b"
  top: "fc7b"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-shapes"
  type: "InnerProduct"
  bottom: "fc7b"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "neg"
  type: "Power"
  bottom: "bbox"
  top: "bbox_neg"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "bbox_neg"
  top: "bbox_neg_flat"
}
layer {
  name: "subtract"
  type: "Eltwise"
  bottom: "fc8"
  bottom: "bbox_neg_flat"
  top: "out_diff"
}
layer {
  name: "abssum"
  type: "Reduction"
  bottom: "out_diff"
  top: "loss"
  loss_weight: 1
  reduction_param {
    operation: ASUM
  }
}
I0912 21:17:13.499811  2840 layer_factory.hpp:77] Creating layer input
I0912 21:17:13.499833  2840 net.cpp:100] Creating Layer input
I0912 21:17:13.499840  2840 net.cpp:408] input -> target
I0912 21:17:13.499868  2840 net.cpp:408] input -> image
I0912 21:17:13.499876  2840 net.cpp:408] input -> bbox
I0912 21:17:13.507874  2840 net.cpp:150] Setting up input
I0912 21:17:13.507911  2840 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0912 21:17:13.507917  2840 net.cpp:157] Top shape: 1 3 227 227 (154587)
I0912 21:17:13.507921  2840 net.cpp:157] Top shape: 1 4 1 1 (4)
I0912 21:17:13.507925  2840 net.cpp:165] Memory required for data: 1236712
I0912 21:17:13.507933  2840 layer_factory.hpp:77] Creating layer conv1
I0912 21:17:13.507956  2840 net.cpp:100] Creating Layer conv1
I0912 21:17:13.507962  2840 net.cpp:434] conv1 <- target
I0912 21:17:13.507974  2840 net.cpp:408] conv1 -> conv1
I0912 21:17:13.620987  2840 net.cpp:150] Setting up conv1
I0912 21:17:13.621023  2840 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0912 21:17:13.621031  2840 net.cpp:165] Memory required for data: 2398312
I0912 21:17:13.621054  2840 layer_factory.hpp:77] Creating layer relu1
I0912 21:17:13.621067  2840 net.cpp:100] Creating Layer relu1
I0912 21:17:13.621073  2840 net.cpp:434] relu1 <- conv1
I0912 21:17:13.621078  2840 net.cpp:395] relu1 -> conv1 (in-place)
I0912 21:17:13.621214  2840 net.cpp:150] Setting up relu1
I0912 21:17:13.621223  2840 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0912 21:17:13.621227  2840 net.cpp:165] Memory required for data: 3559912
I0912 21:17:13.621230  2840 layer_factory.hpp:77] Creating layer pool1
I0912 21:17:13.621240  2840 net.cpp:100] Creating Layer pool1
I0912 21:17:13.621244  2840 net.cpp:434] pool1 <- conv1
I0912 21:17:13.621249  2840 net.cpp:408] pool1 -> pool1
I0912 21:17:13.621299  2840 net.cpp:150] Setting up pool1
I0912 21:17:13.621306  2840 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0912 21:17:13.621310  2840 net.cpp:165] Memory required for data: 3839848
I0912 21:17:13.621314  2840 layer_factory.hpp:77] Creating layer norm1
I0912 21:17:13.621323  2840 net.cpp:100] Creating Layer norm1
I0912 21:17:13.621326  2840 net.cpp:434] norm1 <- pool1
I0912 21:17:13.621331  2840 net.cpp:408] norm1 -> norm1
I0912 21:17:13.621613  2840 net.cpp:150] Setting up norm1
I0912 21:17:13.621623  2840 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0912 21:17:13.621628  2840 net.cpp:165] Memory required for data: 4119784
I0912 21:17:13.621631  2840 layer_factory.hpp:77] Creating layer conv2
I0912 21:17:13.621641  2840 net.cpp:100] Creating Layer conv2
I0912 21:17:13.621645  2840 net.cpp:434] conv2 <- norm1
I0912 21:17:13.621650  2840 net.cpp:408] conv2 -> conv2
I0912 21:17:13.631253  2840 net.cpp:150] Setting up conv2
I0912 21:17:13.631268  2840 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0912 21:17:13.631276  2840 net.cpp:165] Memory required for data: 4661480
I0912 21:17:13.631288  2840 layer_factory.hpp:77] Creating layer relu2
I0912 21:17:13.631294  2840 net.cpp:100] Creating Layer relu2
I0912 21:17:13.631297  2840 net.cpp:434] relu2 <- conv2
I0912 21:17:13.631304  2840 net.cpp:395] relu2 -> conv2 (in-place)
I0912 21:17:13.631433  2840 net.cpp:150] Setting up relu2
I0912 21:17:13.631441  2840 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0912 21:17:13.631444  2840 net.cpp:165] Memory required for data: 5203176
I0912 21:17:13.631448  2840 layer_factory.hpp:77] Creating layer pool2
I0912 21:17:13.631453  2840 net.cpp:100] Creating Layer pool2
I0912 21:17:13.631458  2840 net.cpp:434] pool2 <- conv2
I0912 21:17:13.631463  2840 net.cpp:408] pool2 -> pool2
I0912 21:17:13.631506  2840 net.cpp:150] Setting up pool2
I0912 21:17:13.631515  2840 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0912 21:17:13.631517  2840 net.cpp:165] Memory required for data: 5327080
I0912 21:17:13.631520  2840 layer_factory.hpp:77] Creating layer norm2
I0912 21:17:13.631526  2840 net.cpp:100] Creating Layer norm2
I0912 21:17:13.631531  2840 net.cpp:434] norm2 <- pool2
I0912 21:17:13.631541  2840 net.cpp:408] norm2 -> norm2
I0912 21:17:13.631830  2840 net.cpp:150] Setting up norm2
I0912 21:17:13.631842  2840 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0912 21:17:13.631853  2840 net.cpp:165] Memory required for data: 5450984
I0912 21:17:13.631856  2840 layer_factory.hpp:77] Creating layer conv3
I0912 21:17:13.631865  2840 net.cpp:100] Creating Layer conv3
I0912 21:17:13.631868  2840 net.cpp:434] conv3 <- norm2
I0912 21:17:13.631875  2840 net.cpp:408] conv3 -> conv3
I0912 21:17:13.654538  2840 net.cpp:150] Setting up conv3
I0912 21:17:13.654566  2840 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0912 21:17:13.654572  2840 net.cpp:165] Memory required for data: 5575400
I0912 21:17:13.654587  2840 layer_factory.hpp:77] Creating layer relu3
I0912 21:17:13.654594  2840 net.cpp:100] Creating Layer relu3
I0912 21:17:13.654598  2840 net.cpp:434] relu3 <- conv3
I0912 21:17:13.654605  2840 net.cpp:395] relu3 -> conv3 (in-place)
I0912 21:17:13.654908  2840 net.cpp:150] Setting up relu3
I0912 21:17:13.654919  2840 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0912 21:17:13.654922  2840 net.cpp:165] Memory required for data: 5699816
I0912 21:17:13.654927  2840 layer_factory.hpp:77] Creating layer conv4
I0912 21:17:13.654935  2840 net.cpp:100] Creating Layer conv4
I0912 21:17:13.654939  2840 net.cpp:434] conv4 <- conv3
I0912 21:17:13.654947  2840 net.cpp:408] conv4 -> conv4
I0912 21:17:13.672911  2840 net.cpp:150] Setting up conv4
I0912 21:17:13.672930  2840 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0912 21:17:13.672937  2840 net.cpp:165] Memory required for data: 5775080
I0912 21:17:13.672946  2840 layer_factory.hpp:77] Creating layer relu4
I0912 21:17:13.672953  2840 net.cpp:100] Creating Layer relu4
I0912 21:17:13.672957  2840 net.cpp:434] relu4 <- conv4
I0912 21:17:13.672965  2840 net.cpp:395] relu4 -> conv4 (in-place)
I0912 21:17:13.673089  2840 net.cpp:150] Setting up relu4
I0912 21:17:13.673099  2840 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0912 21:17:13.673102  2840 net.cpp:165] Memory required for data: 5850344
I0912 21:17:13.673106  2840 layer_factory.hpp:77] Creating layer conv1_p
I0912 21:17:13.673115  2840 net.cpp:100] Creating Layer conv1_p
I0912 21:17:13.673118  2840 net.cpp:434] conv1_p <- image
I0912 21:17:13.673125  2840 net.cpp:408] conv1_p -> conv1_p
I0912 21:17:13.674886  2840 net.cpp:150] Setting up conv1_p
I0912 21:17:13.674898  2840 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0912 21:17:13.674902  2840 net.cpp:165] Memory required for data: 7011944
I0912 21:17:13.674911  2840 layer_factory.hpp:77] Creating layer relu1_p
I0912 21:17:13.674916  2840 net.cpp:100] Creating Layer relu1_p
I0912 21:17:13.674921  2840 net.cpp:434] relu1_p <- conv1_p
I0912 21:17:13.674926  2840 net.cpp:395] relu1_p -> conv1_p (in-place)
I0912 21:17:13.675093  2840 net.cpp:150] Setting up relu1_p
I0912 21:17:13.675102  2840 net.cpp:157] Top shape: 1 96 55 55 (290400)
I0912 21:17:13.675107  2840 net.cpp:165] Memory required for data: 8173544
I0912 21:17:13.675109  2840 layer_factory.hpp:77] Creating layer pool1_p
I0912 21:17:13.675117  2840 net.cpp:100] Creating Layer pool1_p
I0912 21:17:13.675119  2840 net.cpp:434] pool1_p <- conv1_p
I0912 21:17:13.675124  2840 net.cpp:408] pool1_p -> pool1_p
I0912 21:17:13.675178  2840 net.cpp:150] Setting up pool1_p
I0912 21:17:13.675196  2840 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0912 21:17:13.675199  2840 net.cpp:165] Memory required for data: 8453480
I0912 21:17:13.675216  2840 layer_factory.hpp:77] Creating layer norm1_p
I0912 21:17:13.675226  2840 net.cpp:100] Creating Layer norm1_p
I0912 21:17:13.675230  2840 net.cpp:434] norm1_p <- pool1_p
I0912 21:17:13.675235  2840 net.cpp:408] norm1_p -> norm1_p
I0912 21:17:13.675670  2840 net.cpp:150] Setting up norm1_p
I0912 21:17:13.675683  2840 net.cpp:157] Top shape: 1 96 27 27 (69984)
I0912 21:17:13.675685  2840 net.cpp:165] Memory required for data: 8733416
I0912 21:17:13.675689  2840 layer_factory.hpp:77] Creating layer conv2_p
I0912 21:17:13.675698  2840 net.cpp:100] Creating Layer conv2_p
I0912 21:17:13.675706  2840 net.cpp:434] conv2_p <- norm1_p
I0912 21:17:13.675714  2840 net.cpp:408] conv2_p -> conv2_p
I0912 21:17:13.684989  2840 net.cpp:150] Setting up conv2_p
I0912 21:17:13.685011  2840 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0912 21:17:13.685019  2840 net.cpp:165] Memory required for data: 9275112
I0912 21:17:13.685029  2840 layer_factory.hpp:77] Creating layer relu2_p
I0912 21:17:13.685036  2840 net.cpp:100] Creating Layer relu2_p
I0912 21:17:13.685040  2840 net.cpp:434] relu2_p <- conv2_p
I0912 21:17:13.685045  2840 net.cpp:395] relu2_p -> conv2_p (in-place)
I0912 21:17:13.685192  2840 net.cpp:150] Setting up relu2_p
I0912 21:17:13.685214  2840 net.cpp:157] Top shape: 1 256 23 23 (135424)
I0912 21:17:13.685217  2840 net.cpp:165] Memory required for data: 9816808
I0912 21:17:13.685230  2840 layer_factory.hpp:77] Creating layer pool2_p
I0912 21:17:13.685236  2840 net.cpp:100] Creating Layer pool2_p
I0912 21:17:13.685240  2840 net.cpp:434] pool2_p <- conv2_p
I0912 21:17:13.685245  2840 net.cpp:408] pool2_p -> pool2_p
I0912 21:17:13.685291  2840 net.cpp:150] Setting up pool2_p
I0912 21:17:13.685297  2840 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0912 21:17:13.685302  2840 net.cpp:165] Memory required for data: 9940712
I0912 21:17:13.685304  2840 layer_factory.hpp:77] Creating layer norm2_p
I0912 21:17:13.685312  2840 net.cpp:100] Creating Layer norm2_p
I0912 21:17:13.685314  2840 net.cpp:434] norm2_p <- pool2_p
I0912 21:17:13.685319  2840 net.cpp:408] norm2_p -> norm2_p
I0912 21:17:13.685606  2840 net.cpp:150] Setting up norm2_p
I0912 21:17:13.685619  2840 net.cpp:157] Top shape: 1 256 11 11 (30976)
I0912 21:17:13.685622  2840 net.cpp:165] Memory required for data: 10064616
I0912 21:17:13.685626  2840 layer_factory.hpp:77] Creating layer conv3_p
I0912 21:17:13.685634  2840 net.cpp:100] Creating Layer conv3_p
I0912 21:17:13.685638  2840 net.cpp:434] conv3_p <- norm2_p
I0912 21:17:13.685643  2840 net.cpp:408] conv3_p -> conv3_p
I0912 21:17:13.708338  2840 net.cpp:150] Setting up conv3_p
I0912 21:17:13.708365  2840 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0912 21:17:13.708374  2840 net.cpp:165] Memory required for data: 10189032
I0912 21:17:13.708384  2840 layer_factory.hpp:77] Creating layer relu3_p
I0912 21:17:13.708391  2840 net.cpp:100] Creating Layer relu3_p
I0912 21:17:13.708395  2840 net.cpp:434] relu3_p <- conv3_p
I0912 21:17:13.708400  2840 net.cpp:395] relu3_p -> conv3_p (in-place)
I0912 21:17:13.708663  2840 net.cpp:150] Setting up relu3_p
I0912 21:17:13.708674  2840 net.cpp:157] Top shape: 1 384 9 9 (31104)
I0912 21:17:13.708678  2840 net.cpp:165] Memory required for data: 10313448
I0912 21:17:13.708681  2840 layer_factory.hpp:77] Creating layer conv4_p
I0912 21:17:13.708691  2840 net.cpp:100] Creating Layer conv4_p
I0912 21:17:13.708695  2840 net.cpp:434] conv4_p <- conv3_p
I0912 21:17:13.708703  2840 net.cpp:408] conv4_p -> conv4_p
I0912 21:17:13.726622  2840 net.cpp:150] Setting up conv4_p
I0912 21:17:13.726640  2840 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0912 21:17:13.726649  2840 net.cpp:165] Memory required for data: 10388712
I0912 21:17:13.726658  2840 layer_factory.hpp:77] Creating layer relu4_p
I0912 21:17:13.726666  2840 net.cpp:100] Creating Layer relu4_p
I0912 21:17:13.726670  2840 net.cpp:434] relu4_p <- conv4_p
I0912 21:17:13.726675  2840 net.cpp:395] relu4_p -> conv4_p (in-place)
I0912 21:17:13.726802  2840 net.cpp:150] Setting up relu4_p
I0912 21:17:13.726811  2840 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0912 21:17:13.726825  2840 net.cpp:165] Memory required for data: 10463976
I0912 21:17:13.726829  2840 layer_factory.hpp:77] Creating layer concat
I0912 21:17:13.726835  2840 net.cpp:100] Creating Layer concat
I0912 21:17:13.726850  2840 net.cpp:434] concat <- conv4
I0912 21:17:13.726855  2840 net.cpp:434] concat <- conv4_p
I0912 21:17:13.726871  2840 net.cpp:408] concat -> conv4_concat
I0912 21:17:13.726915  2840 net.cpp:150] Setting up concat
I0912 21:17:13.726922  2840 net.cpp:157] Top shape: 1 768 7 7 (37632)
I0912 21:17:13.726925  2840 net.cpp:165] Memory required for data: 10614504
I0912 21:17:13.726934  2840 layer_factory.hpp:77] Creating layer fc6-new
I0912 21:17:13.726943  2840 net.cpp:100] Creating Layer fc6-new
I0912 21:17:13.726953  2840 net.cpp:434] fc6-new <- conv4_concat
I0912 21:17:13.726958  2840 net.cpp:408] fc6-new -> fc6
I0912 21:17:17.575220  2840 net.cpp:150] Setting up fc6-new
I0912 21:17:17.575259  2840 net.cpp:157] Top shape: 1 4096 (4096)
I0912 21:17:17.575268  2840 net.cpp:165] Memory required for data: 10630888
I0912 21:17:17.575285  2840 layer_factory.hpp:77] Creating layer relu6
I0912 21:17:17.575297  2840 net.cpp:100] Creating Layer relu6
I0912 21:17:17.575312  2840 net.cpp:434] relu6 <- fc6
I0912 21:17:17.575320  2840 net.cpp:395] relu6 -> fc6 (in-place)
I0912 21:17:17.575702  2840 net.cpp:150] Setting up relu6
I0912 21:17:17.575713  2840 net.cpp:157] Top shape: 1 4096 (4096)
I0912 21:17:17.575717  2840 net.cpp:165] Memory required for data: 10647272
I0912 21:17:17.575721  2840 layer_factory.hpp:77] Creating layer drop6
I0912 21:17:17.575727  2840 net.cpp:100] Creating Layer drop6
I0912 21:17:17.575731  2840 net.cpp:434] drop6 <- fc6
I0912 21:17:17.575737  2840 net.cpp:395] drop6 -> fc6 (in-place)
I0912 21:17:17.575770  2840 net.cpp:150] Setting up drop6
I0912 21:17:17.575778  2840 net.cpp:157] Top shape: 1 4096 (4096)
I0912 21:17:17.575781  2840 net.cpp:165] Memory required for data: 10663656
I0912 21:17:17.575784  2840 layer_factory.hpp:77] Creating layer fc7-new
I0912 21:17:17.575793  2840 net.cpp:100] Creating Layer fc7-new
I0912 21:17:17.575798  2840 net.cpp:434] fc7-new <- fc6
I0912 21:17:17.575803  2840 net.cpp:408] fc7-new -> fc7
I0912 21:17:17.784229  2840 net.cpp:150] Setting up fc7-new
I0912 21:17:17.784267  2840 net.cpp:157] Top shape: 1 2048 (2048)
I0912 21:17:17.784276  2840 net.cpp:165] Memory required for data: 10671848
I0912 21:17:17.784291  2840 layer_factory.hpp:77] Creating layer relu7
I0912 21:17:17.784301  2840 net.cpp:100] Creating Layer relu7
I0912 21:17:17.784307  2840 net.cpp:434] relu7 <- fc7
I0912 21:17:17.784315  2840 net.cpp:395] relu7 -> fc7 (in-place)
I0912 21:17:17.784507  2840 net.cpp:150] Setting up relu7
I0912 21:17:17.784518  2840 net.cpp:157] Top shape: 1 2048 (2048)
I0912 21:17:17.784521  2840 net.cpp:165] Memory required for data: 10680040
I0912 21:17:17.784525  2840 layer_factory.hpp:77] Creating layer drop7
I0912 21:17:17.784531  2840 net.cpp:100] Creating Layer drop7
I0912 21:17:17.784535  2840 net.cpp:434] drop7 <- fc7
I0912 21:17:17.784540  2840 net.cpp:395] drop7 -> fc7 (in-place)
I0912 21:17:17.784579  2840 net.cpp:150] Setting up drop7
I0912 21:17:17.784586  2840 net.cpp:157] Top shape: 1 2048 (2048)
I0912 21:17:17.784590  2840 net.cpp:165] Memory required for data: 10688232
I0912 21:17:17.784593  2840 layer_factory.hpp:77] Creating layer fc7-newb
I0912 21:17:17.784605  2840 net.cpp:100] Creating Layer fc7-newb
I0912 21:17:17.784610  2840 net.cpp:434] fc7-newb <- fc7
I0912 21:17:17.784615  2840 net.cpp:408] fc7-newb -> fc7b
I0912 21:17:17.836549  2840 net.cpp:150] Setting up fc7-newb
I0912 21:17:17.836585  2840 net.cpp:157] Top shape: 1 1024 (1024)
I0912 21:17:17.836593  2840 net.cpp:165] Memory required for data: 10692328
I0912 21:17:17.836606  2840 layer_factory.hpp:77] Creating layer relu7b
I0912 21:17:17.836616  2840 net.cpp:100] Creating Layer relu7b
I0912 21:17:17.836622  2840 net.cpp:434] relu7b <- fc7b
I0912 21:17:17.836630  2840 net.cpp:395] relu7b -> fc7b (in-place)
I0912 21:17:17.836987  2840 net.cpp:150] Setting up relu7b
I0912 21:17:17.836998  2840 net.cpp:157] Top shape: 1 1024 (1024)
I0912 21:17:17.837002  2840 net.cpp:165] Memory required for data: 10696424
I0912 21:17:17.837007  2840 layer_factory.hpp:77] Creating layer drop7b
I0912 21:17:17.837013  2840 net.cpp:100] Creating Layer drop7b
I0912 21:17:17.837016  2840 net.cpp:434] drop7b <- fc7b
I0912 21:17:17.837025  2840 net.cpp:395] drop7b -> fc7b (in-place)
I0912 21:17:17.837056  2840 net.cpp:150] Setting up drop7b
I0912 21:17:17.837064  2840 net.cpp:157] Top shape: 1 1024 (1024)
I0912 21:17:17.837067  2840 net.cpp:165] Memory required for data: 10700520
I0912 21:17:17.837077  2840 layer_factory.hpp:77] Creating layer fc8-shapes
I0912 21:17:17.837085  2840 net.cpp:100] Creating Layer fc8-shapes
I0912 21:17:17.837095  2840 net.cpp:434] fc8-shapes <- fc7b
I0912 21:17:17.837102  2840 net.cpp:408] fc8-shapes -> fc8
I0912 21:17:17.837322  2840 net.cpp:150] Setting up fc8-shapes
I0912 21:17:17.837330  2840 net.cpp:157] Top shape: 1 4 (4)
I0912 21:17:17.837334  2840 net.cpp:165] Memory required for data: 10700536
I0912 21:17:17.837339  2840 layer_factory.hpp:77] Creating layer neg
I0912 21:17:17.837345  2840 net.cpp:100] Creating Layer neg
I0912 21:17:17.837349  2840 net.cpp:434] neg <- bbox
I0912 21:17:17.837354  2840 net.cpp:408] neg -> bbox_neg
I0912 21:17:17.837380  2840 net.cpp:150] Setting up neg
I0912 21:17:17.837386  2840 net.cpp:157] Top shape: 1 4 1 1 (4)
I0912 21:17:17.837389  2840 net.cpp:165] Memory required for data: 10700552
I0912 21:17:17.837393  2840 layer_factory.hpp:77] Creating layer flatten
I0912 21:17:17.837399  2840 net.cpp:100] Creating Layer flatten
I0912 21:17:17.837401  2840 net.cpp:434] flatten <- bbox_neg
I0912 21:17:17.837405  2840 net.cpp:408] flatten -> bbox_neg_flat
I0912 21:17:17.837431  2840 net.cpp:150] Setting up flatten
I0912 21:17:17.837437  2840 net.cpp:157] Top shape: 1 4 (4)
I0912 21:17:17.837440  2840 net.cpp:165] Memory required for data: 10700568
I0912 21:17:17.837443  2840 layer_factory.hpp:77] Creating layer subtract
I0912 21:17:17.837448  2840 net.cpp:100] Creating Layer subtract
I0912 21:17:17.837451  2840 net.cpp:434] subtract <- fc8
I0912 21:17:17.837455  2840 net.cpp:434] subtract <- bbox_neg_flat
I0912 21:17:17.837462  2840 net.cpp:408] subtract -> out_diff
I0912 21:17:17.837488  2840 net.cpp:150] Setting up subtract
I0912 21:17:17.837494  2840 net.cpp:157] Top shape: 1 4 (4)
I0912 21:17:17.837497  2840 net.cpp:165] Memory required for data: 10700584
I0912 21:17:17.837501  2840 layer_factory.hpp:77] Creating layer abssum
I0912 21:17:17.837505  2840 net.cpp:100] Creating Layer abssum
I0912 21:17:17.837509  2840 net.cpp:434] abssum <- out_diff
I0912 21:17:17.837514  2840 net.cpp:408] abssum -> loss
I0912 21:17:17.837540  2840 net.cpp:150] Setting up abssum
I0912 21:17:17.837548  2840 net.cpp:157] Top shape: (1)
I0912 21:17:17.837550  2840 net.cpp:160]     with loss weight 1
I0912 21:17:17.837565  2840 net.cpp:165] Memory required for data: 10700588
I0912 21:17:17.837569  2840 net.cpp:226] abssum needs backward computation.
I0912 21:17:17.837573  2840 net.cpp:226] subtract needs backward computation.
I0912 21:17:17.837576  2840 net.cpp:228] flatten does not need backward computation.
I0912 21:17:17.837579  2840 net.cpp:228] neg does not need backward computation.
I0912 21:17:17.837584  2840 net.cpp:226] fc8-shapes needs backward computation.
I0912 21:17:17.837586  2840 net.cpp:226] drop7b needs backward computation.
I0912 21:17:17.837589  2840 net.cpp:226] relu7b needs backward computation.
I0912 21:17:17.837592  2840 net.cpp:226] fc7-newb needs backward computation.
I0912 21:17:17.837596  2840 net.cpp:226] drop7 needs backward computation.
I0912 21:17:17.837599  2840 net.cpp:226] relu7 needs backward computation.
I0912 21:17:17.837604  2840 net.cpp:226] fc7-new needs backward computation.
I0912 21:17:17.837606  2840 net.cpp:226] drop6 needs backward computation.
I0912 21:17:17.837610  2840 net.cpp:226] relu6 needs backward computation.
I0912 21:17:17.837612  2840 net.cpp:226] fc6-new needs backward computation.
I0912 21:17:17.837616  2840 net.cpp:226] concat needs backward computation.
I0912 21:17:17.837620  2840 net.cpp:226] relu4_p needs backward computation.
I0912 21:17:17.837623  2840 net.cpp:226] conv4_p needs backward computation.
I0912 21:17:17.837626  2840 net.cpp:226] relu3_p needs backward computation.
I0912 21:17:17.837630  2840 net.cpp:226] conv3_p needs backward computation.
I0912 21:17:17.837632  2840 net.cpp:226] norm2_p needs backward computation.
I0912 21:17:17.837637  2840 net.cpp:226] pool2_p needs backward computation.
I0912 21:17:17.837641  2840 net.cpp:226] relu2_p needs backward computation.
I0912 21:17:17.837646  2840 net.cpp:226] conv2_p needs backward computation.
I0912 21:17:17.837651  2840 net.cpp:226] norm1_p needs backward computation.
I0912 21:17:17.837656  2840 net.cpp:226] pool1_p needs backward computation.
I0912 21:17:17.837661  2840 net.cpp:226] relu1_p needs backward computation.
I0912 21:17:17.837663  2840 net.cpp:226] conv1_p needs backward computation.
I0912 21:17:17.837667  2840 net.cpp:226] relu4 needs backward computation.
I0912 21:17:17.837671  2840 net.cpp:226] conv4 needs backward computation.
I0912 21:17:17.837673  2840 net.cpp:226] relu3 needs backward computation.
I0912 21:17:17.837677  2840 net.cpp:226] conv3 needs backward computation.
I0912 21:17:17.837680  2840 net.cpp:226] norm2 needs backward computation.
I0912 21:17:17.837683  2840 net.cpp:226] pool2 needs backward computation.
I0912 21:17:17.837687  2840 net.cpp:226] relu2 needs backward computation.
I0912 21:17:17.837690  2840 net.cpp:226] conv2 needs backward computation.
I0912 21:17:17.837693  2840 net.cpp:226] norm1 needs backward computation.
I0912 21:17:17.837697  2840 net.cpp:226] pool1 needs backward computation.
I0912 21:17:17.837700  2840 net.cpp:226] relu1 needs backward computation.
I0912 21:17:17.837703  2840 net.cpp:226] conv1 needs backward computation.
I0912 21:17:17.837707  2840 net.cpp:228] input does not need backward computation.
I0912 21:17:17.837710  2840 net.cpp:270] This network produces output loss
I0912 21:17:17.837728  2840 net.cpp:283] Network initialization done.
F0912 21:17:17.837858  2840 upgrade_proto.cpp:86] Check failed: ReadProtoFromBinaryFile(param_file, param) Failed to parse NetParameter file: nets/models/ptr_smlr_scrtch_npd/solverstate/caffenet_train_iter_600000.solverstate
*** Check failure stack trace: ***
    @     0x7f2810e12daa  (unknown)
    @     0x7f2810e12ce4  (unknown)
    @     0x7f2810e126e6  (unknown)
    @     0x7f2810e15687  (unknown)
    @     0x7f2812021987  caffe::ReadNetParamsFromBinaryFileOrDie()
    @     0x7f281205280a  caffe::Net<>::CopyTrainedLayersFromBinaryProto()
    @     0x7f2812052891  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x434695  Regressor::SetupNetwork()
    @           0x434adf  Regressor::Regressor()
    @           0x43919d  RegressorTrain::RegressorTrain()
    @           0x412cd9  main
    @     0x7f280f8faf45  (unknown)
    @           0x4147d7  (unknown)
    @              (nil)  (unknown)
